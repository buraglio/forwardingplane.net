<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>
    How-To on ForwardingPlane.net
    
    </title>
    <link>https://forwardingplane.net/tags/how-to/</link>
    <description>Recent content 
    
    in How-To on ForwardingPlane.net
    </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
    
    <copyright>Copyright (c) 2019, all rights reserved.</copyright>
    <lastBuildDate>Sun, 08 Sep 2019 18:11:58 +0000</lastBuildDate>
    
    
        <atom:link href="https://forwardingplane.net/tags/how-to/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ElastiFlow Template VM</title>
      <link>https://forwardingplane.net/post/elastiflow-template-vm/</link>
      <pubDate>Sun, 08 Sep 2019 18:11:58 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/elastiflow-template-vm/</guid>
      <description>&lt;p&gt;Flow data is a critical piece of understanding how your network works what what it is actively doing. It also provides a great baseline and capacity planning tool. However, some of the more feature rich NetFlow and/or sFlow collectors can be quite daunting in their cost and/or complexity to install. &lt;a href=&#34;https://github.com/robcowart/elastiflow&#34;&gt;ElastiFlow&lt;/a&gt; is a great alternative for flow analytics and is built on the well traveled and robust &lt;a href=&#34;https://www.elastic.co/start?ultron=[EL]-[B]-[AMER]-US+CA-Exact&amp;amp;blade=adwords-s&amp;amp;Device=c&amp;amp;thor=elastic%20stack&amp;amp;gclid=EAIaIQobChMIuKC5xefB5AIVCYnICh0wEg5lEAAYASAAEgIp_fD_BwE&#34;&gt;ElasticStack&lt;/a&gt;, meaning, its back end is well documented, well supported, and scales exceptionally well. For those that would like to play around with this but don&amp;rsquo;t want to take the time to install it (see below for the instruction set I used), I have provided a simple VM to toy around with.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2019/09/Screen-Shot-2019-09-07-at-11.00.35-PM-1024x704.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Included here is a vanilla Ubuntu 18 LTS VM with a basic &lt;a href=&#34;https://github.com/robcowart/elastiflow&#34;&gt;Elastiflow&lt;/a&gt; install. This includes all of the components of an ElasticStack plus the front end pieces of the ElastiFlow project. Most of the install is based on &lt;a href=&#34;https://www.catapultsystems.com/blogs/install-elastiflow-on-ubuntu-18-04-part-1/&#34;&gt;this&lt;/a&gt; how-to. &lt;/p&gt;

&lt;p&gt;Included in the image is also a base install of NGINX and certbot so that you can reverse proxy the access and have a valid SSL certificate. There are a plethora of guides on how to accomplish that task on the internet.&lt;/p&gt;

&lt;p&gt;This was build and validated on Proxmox 6.0.6 but should be able to run on VMWare as well with a bit of qemu-img conversion. As expected, ElastiFlow (and ElasticStack) are fairly resource hungry. 16G of Memory and a handful of CPU cores is the bare minimum to run this with any real efficiency. Additionally, Ubuntu 18 has changed how the networking is setup - it is all located in /etc/netplan/ now.   &lt;/p&gt;

&lt;p&gt;Login Information:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;User Name: root
Password: elastiflow
Privileged user: elastiflow
Password: elastiflow  

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Default IP addresses:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10.255.255.5/27
2001:db8:ffff:2::5/64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download the image &lt;a href=&#34;https://drive.google.com/open?id=1ga_Pj2j6h1ce9rcT7jQjncpVjLIC4X4t&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Basic automation for WISPs and small to medium ISPs</title>
      <link>https://forwardingplane.net/post/basic-automation-for-wisps-and-small-to-medium-isps/</link>
      <pubDate>Mon, 29 Jul 2019 09:39:35 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/basic-automation-for-wisps-and-small-to-medium-isps/</guid>
      <description>&lt;p&gt;Small to medium ISPs are an interesting phenomenon. Early in my career I was pretty heavily involved in that space, so much of my current thought processes and methodologies are heavily informed by that experience. Something that never ceases to amaze me today is that the practice of scripting and “automating” things seems to have become somewhat of a lost art, or at the very least it is not part of an initial deployment plan. As I learned to operate a network at scale and with efficiency, we used a significant amount of perl to automate repetitive tasks such as user creation for ppp profiles, provisioning DSL CPE, checking status of PRI and ATM VPCs, etc. In the many years that have passed since my introduction to ISP architecture and operation, the internet has gone from a luxury item to a required utility. In this lapsed time, specialization in networking has become far more prevalent and the generalist role has been significantly diminished. With that specialization and commoditization of IT, the prevalence of the network engineer that could write code became more and more uncommon. Then came “automation”. As we realized that the ubiquitous nature of IT systems and services was only going to increase, automation platforms and companies operating those platforms started to spring up. No longer was there a need to learn hardcore perl, python, shell programming. There were frameworks such as &lt;a href=&#34;https://cfengine.com/&#34;&gt;cfengine&lt;/a&gt;, &lt;a href=&#34;https://puppet.com/&#34;&gt;puppet&lt;/a&gt;, &lt;a href=&#34;https://www.saltstack.com/&#34;&gt;salt&lt;/a&gt;, and &lt;a href=&#34;https://www.ansible.com/&#34;&gt;ansible&lt;/a&gt; that could abstract some of that away and provide significant functionality in addition. I did extensive work with cfengine and did production deployments of salt. In addition, I was around for production deployments of puppet, but it wasn’t until I played with Ansible a few years ago that I got really interested in the automation space - but not really automation, per se. It was far more interesting to me to work on orchestrating workflows. Ansible was perfect for this due to its extreme flexibility and its ability to natively talk to network hardware. So I wrote some Ansible. Then I was informed that my ansible was poor form (which it definitely was). At that point I spent some time learning and playing. Then other things came along and I set it aside for a few years. Well, this past month my interest has ben re-ignited (mainly due to the inclusion of a &lt;a href=&#34;https://docs.ansible.com/ansible/latest/network/user_guide/platform_routeros.html&#34;&gt;mikrotik routeos ansible module&lt;/a&gt;). I spent some time with my &lt;a href=&#34;https://twitter.com/samoehlert&#34;&gt;local ansible guru&lt;/a&gt; and he taught me the best practices and from there I was off to the races. After a bit of re-education, I have compiled a few very simple ansible roles and playbooks focused mostly on the WISP world (because I have a lot of this type of gear in my lab), but I fully expect to expand on them greatly as they are all part of a larger bunch of orchestration parts that I have been writing at night and in my free time. Until then, please feel free to use, modify, or provide patches / input for what I have published thus far. &lt;img src=&#34;https://www.forwardingplane.net/wp-content/uploads/2019/07/transparent-ansible-logo.png&#34; alt=&#34;Transparent ansible logo&#34; title=&#34;transparent-ansible-logo.png&#34; /&gt; &lt;a href=&#34;https://github.com/buraglio/mikrotik-armor&#34;&gt;mikrotik-armor&lt;/a&gt; Simple Ansible role and playbook to harden a Mikrotik RouterOS device &lt;a href=&#34;https://github.com/buraglio/upgrade-mikrotik-routeros&#34;&gt;upgrade-mikrotik-routeros&lt;/a&gt; Simple Ansible playbook and role for setting a software channel and upgrading RouterOS on mikrotik devices &lt;a href=&#34;https://github.com/buraglio/ubnt-airos-tshaper&#34;&gt;ubnt-airos-tshaper&lt;/a&gt; Ansible playbooks to enable and configure the traffic shaper on Ubiquity AirOS CPE&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The value of measurements: Network Latency</title>
      <link>https://forwardingplane.net/post/the-value-of-measurements-network-latency/</link>
      <pubDate>Mon, 29 Apr 2019 10:23:32 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/the-value-of-measurements-network-latency/</guid>
      <description>&lt;p&gt;There is no shortage of network telemetry data that can be collected, recorded, graphed, and stored for cross reference and triage. Not one to be underestimated, latency at a can be incredibly powerful when leveraged for baseline and deviation notification. As I have &lt;a href=&#34;https://www.forwardingplane.net/2018/02/strategy-series-view-outside-network/&#34;&gt;eluded to in the past,&lt;/a&gt; there are many tools in this space. &lt;a href=&#34;https://netbeez.net/blog/how-to-leverage-latency-testing-and-long-term-trend-collection/&#34;&gt;I have written about a few of them in detail&lt;/a&gt; and touched on others in passing. Regardless of the tool, the data is powerful and the instrumentation they provide will only serve to make your network more robust and easier to work on. One tool that is particularly easy to set up and utilize is &lt;a href=&#34;https://oss.oetiker.ch/smokeping/&#34;&gt;smokeping&lt;/a&gt;. From the authors site: &lt;em&gt;SmokePing keeps track of your network latency:&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Best of breed latency visualisation.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Interactive graph explorer.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Wide range of latency measurement plugins.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Master/Slave System for distributed measurement.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Highly configurable alerting system.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Live Latency Charts with the most &amp;lsquo;interesting&amp;rsquo; graphs.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Free and OpenSource Software written in Perl written by Tobi Oetiker, the creator of MRTG and RRDtool &lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.forwardingplane.net/wp-content/uploads/2019/04/download_Comcast_Chicago_last_864000.png&#34; alt=&#34;Download Comcast Chicago last 864000&#34; title=&#34;download_Comcast_Chicago_last_864000.png&#34; /&gt; &lt;em&gt;Comcast SpeedTest.net graph for home network&lt;/em&gt; Now, you may be asking _“why do I need to track latency?_”, well, the data is incredibly powerful and can be indicators of anything from a failing optic to a network compromise. This is especially useful in small to medium sized ISPs (and especially WISPs), where cost of software and operational overhead is at a premium, and customer satisfaction is the currency that is dealt. In fact, I was able to use smokeqping to help diagnose a functional denial of service of a commonly deployed cable CPE as detailed &lt;a href=&#34;https://forums.businesshelp.comcast.com/t5/IPV6/Reproducible-denial-of-service-of-Netgear-CPE-running-native/m-p/31597#M787&#34;&gt;here&lt;/a&gt;. &lt;strong&gt;I can’t emphasize enough how useful long term trend data is.&lt;/strong&gt; Smokeping can be used to monitor more than just ping RTT, it supports a myriad of plugins allowing for application latency of protocols such as DNS queries, http get, ssh daemon response, speed test results, the list of plugins - or as smokeping calls them, probes - goes on and can be found &lt;a href=&#34;https://oss.oetiker.ch/smokeping/probe/index.en.html&#34;&gt;here&lt;/a&gt;. Where this is particularly useful is in simulating customer experience.  As with most things in life, perspective is paramount. To address this, smokeping can also be deployed as a distributed model. Deploying it with installations more local to a customer or in a far flung site, say on a raspberry pi, located in remote POP sides or pedestal locations will provide a closer perspective to what the customer actually sees. In the past I have deployed remote raspberry pi devices in an actual FTTH pedestal connected to an ONT to provide the exact customer point of view and it provided a wealth of information I would not otherwise be able to see. There are a myriad of different instal guides for Smokeping, my recommended starting point is by &lt;a href=&#34;https://github.com/magicdude4eva&#34;&gt;Gerd Naschenweng&lt;/a&gt; and can be found &lt;a href=&#34;https://github.com/magicdude4eva/docker-smokeping&#34;&gt;here&lt;/a&gt;. It provides a docker instance but also has a very good set of configuration files to build examples from. Don’t discount latency data - it’s a powerful set of information for any working network. For anyone interested in seeing a working smokeping installation, mine is public and available to view. It provides a few things such as DNS latency, RTT for v4 and v6, RTT for ZeroTier hosts and RIPE ATLAS probes, etc. It’s a powerful toolkit. My public cloud instance is hosted at &lt;a href=&#34;http://www.prgmr.com&#34;&gt;prgmr.com&lt;/a&gt; and can be found &lt;a href=&#34;https://watcher.forwardingplane.net/smokeping/smokeping.cgi&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DNS - the treasure trove of information your ISP can see</title>
      <link>https://forwardingplane.net/post/dns-the-treasure-trove-of-information-your-isp-can-see/</link>
      <pubDate>Mon, 10 Dec 2018 10:23:42 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/dns-the-treasure-trove-of-information-your-isp-can-see/</guid>
      <description>&lt;p&gt;In recent years, the nature of &lt;a href=&#34;http://fortune.com/2017/11/23/net-neutrality-explained-what-it-means-and-why-it-matters/&#34;&gt;privacy on the internet&lt;/a&gt; has become a very important topic amongst those concerned with the now lack of &lt;a href=&#34;https://www.theverge.com/2017/12/14/16776154/fcc-net-neutrality-vote-results-rules-repealed&#34;&gt;net neutrality&lt;/a&gt;. The de-facto mechanism for dealing with privacy has been to &amp;ldquo;&lt;a href=&#34;https://letsencrypt.org/&#34;&gt;SSL all the things&lt;/a&gt;&amp;rdquo;, which I am very much in favor of. What many do not realize, though, is that simply using SSL for the traffic that transits a given ISP still leaves a wealth of thick, rich, delicious personal data still easily available to your ISP to harvest, sell, and do with as they please. This data comes in the form of DNS queries. DNS is the nearly-always-forgotten, crucial aspect of how the internet functions. Without DNS, nothing works. Everything appears broken and manifest as what appears to be a networking problem. ISPs typically provide what is called a &lt;a href=&#34;https://umbrella.cisco.com/blog/2014/07/16/difference-authoritative-recursive-dns-nameservers/&#34;&gt;recursive resolver&lt;/a&gt;, which for most people is handed down by a local provider to the customer premise equipment (CPE; usually a modem or optical terminal of some kind) that they install at a residence. This CPE then hands that resolver to your clients that use it to - you guessed it - recursively resolve DNS queries. These queries can be logged and then mined for browsing habits, etc. Anyone that has ever done any network forensics will know straight away that the value of the information contained in DNS query logs is very, very high. &lt;/p&gt;

&lt;p&gt;What this means is that even though a privacy conscious individual is hiding the bulk of their content in SSL, meaning the bulk of what they’re reading, searching for, and doing, is encrypted, the requests for that content or activity is not. For example, an ISP can potentially see that a client is making many, many queries for $onlineshopping.com and begin selling that data to advertisers. If you think they’re not doing this now, &lt;a href=&#34;https://www.wired.com/story/can-verizon-build-a-strong-brand-from-the-bones-of-yahoo-and-aol/&#34;&gt;think again&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Great, so $bigbadprovider can see your queries. There are a number of pretty good ways to work around this, and &lt;a href=&#34;https://pi-hole.net/&#34;&gt;one of my favorite projects&lt;/a&gt; handily deals with one of them with great simplicity. What I am referring to is the newly popular &lt;a href=&#34;https://scotthelme.co.uk/securing-dns-across-all-of-my-devices-with-pihole-dns-over-https-1-1-1-1/&#34;&gt;DNS over HTTPS&lt;/a&gt;, which is supported by the &lt;a href=&#34;https://one.one.one.one/&#34;&gt;cloudflare 1.1.1.1 service&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;So, as a thought experiment I decided to play Reeses Peanut butter and chocolate with two of my favorite technological creations: the aforementioned PiHole, and &lt;a href=&#34;https://zerotier.com/&#34;&gt;ZeroTier&lt;/a&gt;. Now anyone that isn’t familiar with ZeroTier, you should acquaint yourself - Packet Pushers did a good &lt;a href=&#34;https://packetpushers.net/podcast/pq-134-meet-zerotier-open-source-networking/&#34;&gt;podcast on it back in November of 2017&lt;/a&gt;. It’s functionally an encrypted overlay supporting dual stack networking with auto configuration and gateway capabilities, and it runs on almost everything. I love this overlay technology and have been using it for a while - highly recommended.&lt;/p&gt;

&lt;p&gt;Back to my peanut butter and chocolate experiment. So, given that I had an existing ZeroTier network and an existing PiHole setup at home, I went over to &lt;a href=&#34;https://www.vultr.com/?ref=7692870&#34;&gt;Vultr.com&lt;/a&gt; and spun up a small VM for $3.50/mo, integrated it into my fleet with my Ansible and Salt tools, and installed ZeroTier and Pihole. From there I set up this DNS hierarchy. &lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://docs.google.com/drawings/d/e/2PACX-1vS-DsmzNWvE335KZtNo6AHX3SySG-VQWhK7i9sNgT6mFMHC5VzRWtMuJg5JraU2dJTFQT4QIGnfaMFP/pub?w=960&amp;amp;h=720&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What this buys me is a fully encrypted DNS path up through the Vultr.com VM host without modifying the underlying DNS transport. And it works surprisingly well. I ran SmokePing from two hosts - both leveraging ZeroTier to do their testing, one on my local network and one in the cloud - to measure latency for a few days before I did this and kept that running after the deployment. Now, it’s not perfect but my family and I have been using this for about a month with minimal issues. Once in a great while we’ll see some slow DNS resolution time, but overall it works fairly well. &lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.forwardingplane.net/wp-content/uploads/2018/12/Resolver-Queries.png&#34; alt=&#34;Resolver Queries&#34; title=&#34;Resolver Queries.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My take &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The idea of using a public resolver kinda bothers me, I realize it’s probably unfounded, but I know how to and have run resolvers for ISPs and organizations for like 20 years, so I have the burden of knowledge about what is in the logs and how to run my own. Using a secured recursive resolver is simply trading transit privacy for lack of query privacy somewhere else. Then there is the issue of content networks that use DNS queries to take you to the best / topologically closest cache of their content [NOTE: this, along with the forensics data for debugging potential security issues is a &lt;strong&gt;top&lt;/strong&gt; reason that all ISPs should run their own resolvers]. I fully realize that a normal end user running their own resolver is unlikely and that this deployment is a bit overkill. However, as I can demonstrably prove, it works. And it works pretty well. It also has the added bonus of allowing me to have internal DNS resolution of my own hosts and any mobile ZeroTier client. Is it for everyone? No way. Does it prove viability for low/medium traffic use? Sure. The point is really just to get folks thinking about information leaking that they may not have considered. The nature of the internet makes true privacy pretty much impossible, but there are a few ways to make your data a little harder to for companies to compile and capitalize on if you truly don’t want them to.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Faucet: Enterprise OpenFlow in production</title>
      <link>https://forwardingplane.net/post/faucet-enterprise-openflow-in-production/</link>
      <pubDate>Mon, 05 Nov 2018 10:56:21 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/faucet-enterprise-openflow-in-production/</guid>
      <description>

&lt;p&gt;Remember OpenFlow? It was the media and marketing darling for the better part of 5 years as “the machine” conflated OpenFlow with SDN and SDN with - almost literally - everything. &amp;ldquo;Still Does Nothing&amp;rdquo; was a common phrase uttered around those of us that had run large scale, complex networks for a long time. Quietly, &lt;a href=&#34;https://faucet-sdn.blogspot.com/&#34;&gt;and mostly&lt;/a&gt;, out of the fickle media and blogosphere eye, a scrappy little SDN project called &lt;a href=&#34;https://github.com/faucetsdn/faucet&#34;&gt;faucet&lt;/a&gt; has been &lt;a href=&#34;https://github.com/faucetsdn/faucet&#34;&gt;diligently plugging away&lt;/a&gt; &amp;ndash; making easy to use, production quality, well documented, and very stable code that runs OpenFlow networks quite happily in production and at scale. Oh, did I mention that it&amp;rsquo;s also got a very small footprint? Did I also mention that we&amp;rsquo;ve built a multi-terabit network that scales, transiting IPv4, IPv6, L2/L3 switching as well as routing? Or that faucet can control switches from multiple vendors, including P4 vendors who provide a P4-to-OF bridge, and interoperates with non-SDN networks? Or (and possibly most importantly) that faucet provides automated integration tests, allowing many bugs to be caught early (sometimes even by the switch vendor) before shipping new releases? Well, I should probably mention those things. I&amp;rsquo;ve been lucky enough to have been involved in SDN off and on since around 2009, and I can emphatically say that of the production SDN and OpenFlow networks that I have been intimately involved in, this combination of hardware, software and people has been, hands down, the most rewarding and most supportable. In fact, this has been so supportable and great to work with, we migrated our production branch office over to a set of faucet controlled SDN switches, and will soon migrate first hop routing over to our robust faucet system. &amp;ldquo;However did you do this?!?!&amp;rdquo; you might be inclined to say. Well, I&amp;rsquo;m glad you asked, because I am going to tell you.    First, though, there should be some design goals. As many of the naysayers of SDN will happy point out, &amp;ldquo;what problem are you trying to solve?&amp;rdquo; to that end, here is what our design goals were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Run all layer 2 in via faucet&lt;/li&gt;
&lt;li&gt;Remove need to log into any network elements after deployment (other than firmware updates)&lt;/li&gt;
&lt;li&gt;Centralize management&lt;/li&gt;
&lt;li&gt;Stretch goal to NFV BGP, do first hop L3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Easy enough, right? It really is. For our deployment we leveraged Aruba 2930F switches giving us a wealth of 1G copper ports and a handful of 10G SFP+ ports. Luckily, we already had this gear because as so many that have tried to deploy openflow in the past have seen, all hardware is not created equally. Luckily, the &lt;a href=&#34;https://www.faucet.org.nz/&#34;&gt;faucet foundation&lt;/a&gt; has published a list of requirements for support, and there are a reasonable number of vendors that actually conform. The real key that I learned in this process is that without proper vendor support (which had been several lacking in the past), and without multi-table, OpenFlow is not positioned for success. It comes down to using the right tools for the job, and OpenFlow (as well as SDN) is no different. Originally this post was to detail the process of building this network, much like posts in the past where there has been a “do this, then do that” how-to, it’s more or less unnecessary here. Why? The faucet project is serious, well documented and generally here to work. The expectation is that this is not an enclave, or a science experiment, or a lab. It’s a production network with real people and real traffic. Read that again. The expectation is that this is stable, supportable, and can do in ready to use day-to-day. And it doesn’t disappoint. Installing is a snap, the &lt;a href=&#34;https://docs.faucet.nz/en/latest/tutorials/first_time.html&#34;&gt;documentation&lt;/a&gt; for faucet is fantastic and complete. If there is something missing or a question, the developers are incredibly responsive and very quick to answer and address any issues that may arise. It’s extremely low footprint - it runs very well on a raspberry pi and does not tax a raspberry pi series 2, even with the gauge telemetry interface (there is a &lt;a href=&#34;https://docs.faucet.nz/en/latest/installation.html#installing-on-raspberry-pi&#34;&gt;pre-built pi OS&lt;/a&gt; for anyone that would prefer a more turnkey option). You may be thinking “_But Nick, I need my CLI!!!_” You’re covered - and here is why: the developers use this system. They run real networks with it. Every day. They know what is necessary to manage and maintain a real production network and sometimes that means troubleshooting. Like many engineers that learned on traditional network equipment, most of us prefer a CLI to troubleshoot, so the inclusion of this feature from the controller is not really a surprise. The fctl command provides a reasonable visibility into the operations of the controller and can be augmented and scripted.```
buraglio@faucet:~ $ /usr/bin/fctl &amp;ndash;help&lt;/p&gt;

&lt;p&gt;usage:&lt;/p&gt;

&lt;p&gt;MACs learned on a DP.&lt;/p&gt;

&lt;p&gt;/usr/bin/fctl -n &amp;ndash;endpoints=&lt;a href=&#34;http://172.17.0.1:9302&#34;&gt;http://172.17.0.1:9302&lt;/a&gt; &amp;ndash;metrics=learned_macs &amp;ndash;labels=dp_id:0xb827eb608918&lt;/p&gt;

&lt;p&gt;Status of all DPs&lt;/p&gt;

&lt;p&gt;/usr/bin/fctl -n &amp;ndash;endpoints=&lt;a href=&#34;http://172.17.0.1:9302&#34;&gt;http://172.17.0.1:9302&lt;/a&gt; &amp;ndash;metrics=dp_status&lt;/p&gt;

&lt;p&gt;Retrieve FAUCET/Gauge state using Prometheus variables.&lt;/p&gt;

&lt;p&gt;optional arguments:&lt;/p&gt;

&lt;p&gt;-h, &amp;ndash;help            show this help message and exit&lt;/p&gt;

&lt;p&gt;-n, &amp;ndash;nonzero         nonzero results only&lt;/p&gt;

&lt;p&gt;-e ENDPOINTS, &amp;ndash;endpoints ENDPOINTS&lt;/p&gt;

&lt;p&gt;list of endpoint URLs to query&lt;/p&gt;

&lt;p&gt;-m METRICS, &amp;ndash;metrics METRICS&lt;/p&gt;

&lt;p&gt;list of metrics to query&lt;/p&gt;

&lt;p&gt;-l LABELS, &amp;ndash;labels LABELS&lt;/p&gt;

&lt;p&gt;list of labels that must be present&lt;/p&gt;

&lt;p&gt;&amp;ndash;display-labels DISPLAY_LABELS&lt;/p&gt;

&lt;p&gt;list of labels to filter display by (default all)
```Monitoring is also taken into account in the form of the gauge interface, which provides a nearly-real-time telemetry stream of important and useful information. Leveraging both the wealth of topological information that the controller has at its disposal and a familiar &lt;a href=&#34;https://github.com/prometheus&#34;&gt;prometheus&lt;/a&gt; / &lt;a href=&#34;https://grafana.com/&#34;&gt;grafana&lt;/a&gt; back / front end interface, the oft-touted notion of streaming telemetry is fully - and quite capably - realized. From the perspective of a networking monitoring and statistics geek, this is the cat’s meow. Very, very data rich. &lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2018/11/grafana-screencap.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2018/11/grafana-screencap-1024x275.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; A simple diagram of our office network pretty well explains the decoupled control plane architecture. Keep it simple, architect for success. Fundamentally SDN networks should be designed like other networks, redundant systems, good monitoring, out of band access. A good design principle is that if you wouldn’t do it on a traditional network, you probably shouldn’t do it for an SDN based network.   &lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2018/11/faunet-office.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2018/11/faunet-office.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;   Don’t trust me? Fair enough, check out the &lt;a href=&#34;https://www.waikato.ac.nz/research/units/wand.shtml&#34;&gt;University of Waikato&lt;/a&gt; interface &lt;a href=&#34;https://grafana.redcables.wand.nz/d/000000003/redcables-bgp?orgId=1&#34;&gt;here&lt;/a&gt;. For more interface on the deployment at &lt;a href=&#34;https://wand.net.nz/&#34;&gt;WAND&lt;/a&gt;, check &lt;a href=&#34;https://redcables.wand.nz/&#34;&gt;this link&lt;/a&gt;. You won’t be disappointed.    &lt;/p&gt;

&lt;h2 id=&#34;my-take&#34;&gt;My take&lt;/h2&gt;

&lt;h3 id=&#34;building-and-running-it&#34;&gt;Building and running it&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&#34;https://docs.faucet.nz/en/latest/&#34;&gt;documentation for faucet&lt;/a&gt; is indescribably better than any other SDN project I have worked with over the span of nearly 10 years. &lt;strong&gt;It’s also supportable.&lt;/strong&gt; My office has been running the enterprise network off of faucet for a while now, without issue, and it meets our design goals [stretch goal of BGP NFV is still in process - testing is successful]). It is easy to manage and very information rich. I can see security minded folks being very interested in the ACLs and other such options available.&lt;/p&gt;

&lt;h3 id=&#34;telemetry-and-analytics&#34;&gt;Telemetry and analytics    &lt;/h3&gt;

&lt;p&gt;   Where so many others in this space are talking about their Telemetry solution, this one is already here, complete, and usable. Frankly, I am fully comfortable running a production network on this technology, operationally it is truly easier. From a security perspective, the options added scale well and deliver on their promise. Where OpenFlow was once touted as the networking silver bullet (without a lot of real stick time to prove or disprove it), it has now fallen comfortable into a nice, supportable model.&lt;/p&gt;

&lt;h3 id=&#34;up-next&#34;&gt;Up next….    &lt;/h3&gt;

&lt;p&gt;If you think this is cool, wait until &lt;a href=&#34;https://sc18.supercomputing.org/&#34;&gt;SuperComputing 18&lt;/a&gt;, where we’re deploying a &lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:6461072411969363968/&#34;&gt;first-of-it’s kind network&lt;/a&gt;, all controlled by FAUCET.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Strategy Series: What is your netflow strategy?</title>
      <link>https://forwardingplane.net/post/what-is-your-netflow-strategy/</link>
      <pubDate>Mon, 18 Dec 2017 11:15:30 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/what-is-your-netflow-strategy/</guid>
      <description>

&lt;p&gt;You have one, right? Even if your entire strategy is “collect some flow data”, there is absolutely NO reason not to have a netflow implementation, and frankly, it will save you time and money over time if you make the effort to do it. I love network data and analytics and I have waxed poetic about how important they are at every opportunity. There are a myriad of options for analytics and flow data. If you’re not doing something, you’re doing it wrong. I can go on and on about the importance of network data for budgeting, security, capacity planing, and general knowledge of what your network is actually doing, but that’s for another day (contact me directly if you really want to chat details on that subject). Today is about network flow data - the foundational bits and pieces of what the heck your network, big or small, is actually doing. I’ve been having a breakdance fight with flow data packages for almost two decades, and I’ve jotted down a few of my more notable experiences. Regardless of your needs, budget, abilities, or time, there is a solution for you.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://giphy.com/gifs/breakin-boogaloo-shrimp-11FirB7GcukiwU&#34;&gt;via GIPHY&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;arbor-https-www-arbornetworks-com&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://www.arbornetworks.com/&#34;&gt;Arbor&lt;/a&gt;&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Arbor is the Rolls Royce of flow analytics (and DDoS mitigation) solutions. It does almost everything, has options for managed objects, DDoS scrubbing and alerting capabilities, a magnificent interface, role based access, rainbows and gumdrop houses with lollipop trees. This system is pretty darned amazing - it truly is, and that likely comes from the fact that they were one of the first, and had/have one of the largest install bases for this kind of system. They have turnkey solutions and have the unique position of being in roughly 90% of the worlds legacy tier 1 ISPs, so their DDoS and other security options are strong, fast to update, and &lt;strong&gt;&lt;em&gt;very&lt;/em&gt;&lt;/strong&gt; good. I’ve had great experience with this platform and its API. I like to think of arbor as the commercial ISP brass ring for flow data analytics. They have other solutions for enterprise and campus, but their roots are in strong ISP solutions. They’re pricey, but very, very good. Expect to need at least an FTE to really take full advantage of their very capable ecosystem, but if you dedicated the money and manpower to it, you won’t be sad.&lt;/p&gt;

&lt;h2 id=&#34;splunk-https-www-splunk-com&#34;&gt;&lt;a href=&#34;https://www.splunk.com/&#34;&gt;Splunk&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;We all know spunk as a really nice log and analytic system but what many may not realize is that Splunk is really, really good at network data and analytics as well. It’s pricey, but it’s as close as you’ll get to a turkey solution for a SIEM that can actually scale. It has the notion of customizable dashboards and visualization, as a huge amount of plugins and add on’s, but they come with a legendarily steep price tag. The saying I have always heard is “if you can afford spunk, buy spunk. If you can’t use an ELK stack (noe elastic stack)”. My experience backs this up.&lt;/p&gt;

&lt;h2 id=&#34;elk-elastic-stack-https-www-elastic-co&#34;&gt;&lt;a href=&#34;https://www.elastic.co/&#34;&gt;ELK /Elastic Stack&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;I’m a big fan of this not only because it’s essentially free, but because it’s so extremely flexible and has so many existing projects built around it. I’ve moved my go-to for net flow collection from nfdump to Elastic Stack built around the &lt;a href=&#34;https://www.manitonetworks.com/about-flow-analyzer/&#34;&gt;Manito Networks flowanalyzer&lt;/a&gt; install.   This platform takes a bit more command line jockeying and isn’t entirely turnkey, but it’s crazy flexible, had great eye candy and building the visualizations and dashboards is easy. Notable mention is &lt;a href=&#34;https://github.com/robcowart/elastiflow&#34;&gt;Elastiflow&lt;/a&gt;, which is similar but has a bit more eye candy and leverages log stash. Elastiflow doesn’t have nearly as turnkey of an install (and really has almost no “newbie” install instructions at all - but it’s a strong offering if you already know how to spin up an ELK stack and tune it.&lt;/p&gt;

&lt;h2 id=&#34;nfdump-http-nfdump-sourceforge-net&#34;&gt;&lt;a href=&#34;http://nfdump.sourceforge.net/&#34;&gt;Nfdump&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The venerable nfdump. This is what so many large networks were using (and probably still are) for their raw flow collections. This package scales exceptionally well to huge networks and has so many tools available for the CLI that it’s the de facto standard for raw flow analytics and forensics. I love this system and ran it for many, many, MANY years. It takes a but of time to learn, and may not be the right tool for you if you want a modern GUI, lots of eye candy, or are inexperienced with the UNIX/LINIX command line, but it’s got it where it counts, supports IPFix, Netflow v5, v9 and IPFIX and you can’t dog wrong with it. I have a handy how-to getting it up and running Under CentOS &lt;a href=&#34;https://www.forwardingplane.net/2014/01/install-nfsen-and-nfdump-on-centos-6-5-for-netflow-and-or-sflow-collection/&#34;&gt;here&lt;/a&gt;. When you couple this with something like &lt;a href=&#34;https://github.com/JustinAzoff/flow-indexer&#34;&gt;Justin Azoff’s flow indexer&lt;/a&gt; and &lt;a href=&#34;https://sourceforge.net/projects/nfsen/&#34;&gt;nfsen&lt;/a&gt; on the front end, you’ve got an enviable power user setup ripe for both forensics, tactical work as well as baseline generation.&lt;/p&gt;

&lt;h2 id=&#34;solarwinds-https-www-solarwinds-com&#34;&gt;&lt;a href=&#34;https://www.solarwinds.com/&#34;&gt;SolarWinds&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Solarwinds Orion is the go-to for windows based monitoring. It’s not cheap, but if you’re running a windows based monitoring system, you’re likely an enterprise and have budget for it. I have been impressed with the visualizations of this system and like that it does all of the monitoring in one package - once installed I never have to see windows (and since I can’t efficiently support windows, that’s probably a good thing - someone else will handle the OS work). The price tag can be a bit steep depending on number of nodes monitored, but it does what it claims and commercial support is decent. My one complaint is that I can’t seem to find a way to do raw data queries in a straightforward way. This may be possible and I have just not had the time or mental power to workout out. Overall it’s a worthy monitoring platform if you need your system to run on windows and can afford it. There are some older but still good videos from several Network Field Day events &lt;a href=&#34;http://techfieldday.com/companies/solarwinds/&#34;&gt;here&lt;/a&gt; and I wrote about it from a UNIX users perspective &lt;a href=&#34;https://www.forwardingplane.net/2015/07/solarwinds-orion-from-a-unix-user-point-of-view/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;live-action-networks-live-ux-https-www-liveaction-com-products-live-ux&#34;&gt;&lt;a href=&#34;https://www.liveaction.com/products/live-ux/&#34;&gt;Live Action Networks Live UX&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Another commercial option that has good support and a lot of eye candy. This was born out of work with the US Government and is a really interesting system. I’ve met with these guys several times and their team is super open to taking and feature requests and they have a good product. I first heard about them at &lt;a href=&#34;http://techfieldday.com/appearance/liveaction-presents-at-networking-field-day-7/&#34;&gt;Network Field day 7&lt;/a&gt;, their product was intriguing there and they’ve come a long way since then. Worth looking at for a turnkey solution for things like network analytics, IP-SLA,&lt;/p&gt;

&lt;h2 id=&#34;my-take&#34;&gt;My take&lt;/h2&gt;

&lt;p&gt;I like the power that an indexed set of data provides and I am willing and capable of plowing through the install of a linux based system. I’m also frugal, and for a product to really warrant my money it needs to do something that nothing else does [translated: I am willing and able to support open source solutions].&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2017/12/Screenshot-2017-12-15-20.32.57.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That said, the Manito Networks install of Elk + Kibana (no logstash in this default install) is where I typically land due to the fact that I can get indexed flow data, nice, configurable graphs and trending statistics, and can integrate things like syslog into another index on the same system giving me the tools to do forensics on a number of topics on that system. &lt;a href=&#34;https://gitlab.com/thart/flowanalyzer/blob/master/Install/README.md&#34;&gt;The setup is crazy easy&lt;/a&gt; and really well documented, too. Someone linux-inclined can have it up and collecting flow data (sflow, netflow v5/9 or IPFIX) in an order of about 30 minutes - probably less. The take aways really, though, is that there are options available no matter your skill level or budget, so there is really no reason not to have something.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Creating an internal span port inside proxmox OVS</title>
      <link>https://forwardingplane.net/post/creating-internal-span-port-inside-proxmox-ovs/</link>
      <pubDate>Tue, 21 Mar 2017 03:49:58 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/creating-internal-span-port-inside-proxmox-ovs/</guid>
      <description>&lt;p&gt;In the last few years I have moved all of my virtualization to &lt;a href=&#34;https://www.proxmox.com/en/&#34;&gt;proxmox&lt;/a&gt; and docker. Seeing as I like to look at packets because I am a closet security guy, and being as I have been working off-and-on on a security project in recent times, I wanted to be able to span a port not only from a hardware switch, but also within my software switches. I had been using linux bridge, which I am not a fan of, so when I started down this path I did not look hard to find a way to do so under that platform. Instead I used it as an opportunity to move some of the internal bridges to &lt;a href=&#34;http://openvswitch.org/&#34;&gt;OpenVSwitch&lt;/a&gt;. I wanted to create an OVS span port internally. I had experience with OVS in the past for SDN work that I was doing, but I had never created a mirror port. I briefly thought about using OpenFlow to do it, but the unnecessary complexity was off putting. Instead I chose to create a simple mirror of a span port from my switch. So, traffic flow goes as such: &lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2017/03/OVS-SPAN-1.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2017/03/OVS-SPAN-1.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;     This was fairly trivial, and I was seeing packets in no time. I&amp;rsquo;m not going to go through creating an OVS bridge in proxmox, there are lots of &lt;a href=&#34;https://pve.proxmox.com/wiki/Open_vSwitch&#34;&gt;documents&lt;/a&gt; on how to do that. Once you have your switch port SPAN up and running, and the physical interface in the OVS bridge, you essentially just need to add the following: Create the mirror```
ovs-vsctl &amp;ndash; &amp;ndash;id=@m create mirror name=span &amp;ndash; add bridge vmbr1 mirrors @m&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-Find your ports that you want to mirror - you&#39;ll need the physical port if consuming from a real switch like I am, and the software port of the virtualized analyzer.  Remember, in OVS anything you want to mess with is going to have a UUID. You need to match the interfaces with the UUID to verify. ovs-vsctl list port \_uuid : 42dbd5a9-27c6-4f1b-958b-943f67b6801b bond\_downdelay : 0 bond\_fake\_iface : false bond\_mode : \[\] bond\_updelay : 0 external\_ids : {} fake\_bridge : false interfaces : \[b155454d-db6e-4bb8-af88-7cd6b544c303\] lacp : \[\] mac : \[\] name : &#34;eth1&#34; other\_config : {} qos : \[\] statistics : {} status : {} tag : \[\] trunks : \[\] vlan\_mode : \[\] \_uuid : 85c932b2-4f98-4650-8298-ae9e9ca72796 bond\_downdelay : 0 bond\_fake\_iface : false bond\_mode : \[\] bond\_updelay : 0 external\_ids : {} fake\_bridge : false interfaces : \[5219306f-96ec-440a-ac8b-d949ea18d752\] lacp : \[\] mac : \[\] name : &#34;vmbr1&#34; other\_config : {} qos : \[\] statistics : {} status : {} tag : \[\] trunks : \[\] vlan\_mode : \[\] \_uuid : d53c7323-517f-48a2-9235-4505e654d4b1 bond\_downdelay : 0 bond\_fake\_iface : false bond\_mode : \[\] bond\_updelay : 0 external\_ids : {} fake\_bridge : false interfaces : \[91d52d05-d881-4693-ab5c-fc64b5d87518\] lacp : \[\] mac : \[\] name : &#34;veth100i9&#34; other\_config : {} qos : \[\] statistics : {} status : {} tag : \[\] trunks : \[\] vlan\_mode : \[\] In red we have the interfaces I want to to use. the veth interface is the software port on the VM. Eth1 is the hardware interfce that my switch is spanning traffic to. Pro tip: In OVS, the commands are a little unintuitive to me when talking about mirrors.  &#34;select\_src\_port&#34; and &#34;select\_dst\_port=&#34; is the destination of the traffic flow from an interface and not source and destination of the traffic you are mirroring from the point of view of the in and out ports. Confusing, right? For instance I can monitor the input from one interface and the output of another in the mirror. What we want is the input and output of the same interface to get both directions of traffic. This is not unlike how span ports are configured on your hardware switch, the nomenclature just threw me off.```&#34; data-lang=&#34;Find your ports that you want to mirror - you&#39;ll need the physical port if consuming from a real switch like I am, and the software port of the virtualized analyzer.  Remember, in OVS anything you want to mess with is going to have a UUID. You need to match the interfaces with the UUID to verify. ovs-vsctl list port \_uuid : 42dbd5a9-27c6-4f1b-958b-943f67b6801b bond\_downdelay : 0 bond\_fake\_iface : false bond\_mode : \[\] bond\_updelay : 0 external\_ids : {} fake\_bridge : false interfaces : \[b155454d-db6e-4bb8-af88-7cd6b544c303\] lacp : \[\] mac : \[\] name : &#34;eth1&#34; other\_config : {} qos : \[\] statistics : {} status : {} tag : \[\] trunks : \[\] vlan\_mode : \[\] \_uuid : 85c932b2-4f98-4650-8298-ae9e9ca72796 bond\_downdelay : 0 bond\_fake\_iface : false bond\_mode : \[\] bond\_updelay : 0 external\_ids : {} fake\_bridge : false interfaces : \[5219306f-96ec-440a-ac8b-d949ea18d752\] lacp : \[\] mac : \[\] name : &#34;vmbr1&#34; other\_config : {} qos : \[\] statistics : {} status : {} tag : \[\] trunks : \[\] vlan\_mode : \[\] \_uuid : d53c7323-517f-48a2-9235-4505e654d4b1 bond\_downdelay : 0 bond\_fake\_iface : false bond\_mode : \[\] bond\_updelay : 0 external\_ids : {} fake\_bridge : false interfaces : \[91d52d05-d881-4693-ab5c-fc64b5d87518\] lacp : \[\] mac : \[\] name : &#34;veth100i9&#34; other\_config : {} qos : \[\] statistics : {} status : {} tag : \[\] trunks : \[\] vlan\_mode : \[\] In red we have the interfaces I want to to use. the veth interface is the software port on the VM. Eth1 is the hardware interfce that my switch is spanning traffic to. Pro tip: In OVS, the commands are a little unintuitive to me when talking about mirrors.  &#34;select\_src\_port&#34; and &#34;select\_dst\_port=&#34; is the destination of the traffic flow from an interface and not source and destination of the traffic you are mirroring from the point of view of the in and out ports. Confusing, right? For instance I can monitor the input from one interface and the output of another in the mirror. What we want is the input and output of the same interface to get both directions of traffic. This is not unlike how span ports are configured on your hardware switch, the nomenclature just threw me off.```&#34;&gt;ovs-vsctl set mirror span select\_src\_port=@eth1 select\_dst\_port=@eth1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can also do this with the UUID```
ovs-vsctl set mirror span select_src_port=42dbd5a9-27c6-4f1b-958b-943f67b6801b select_dst_port=42dbd5a9-27c6-4f1b-958b-943f67b6801b&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-Now that we have the source of our mirror we just need to send it somewhere. I wanted mine to go to an internal host running some analytics software (on interface veth100i9)```&#34; data-lang=&#34;Now that we have the source of our mirror we just need to send it somewhere. I wanted mine to go to an internal host running some analytics software (on interface veth100i9)```&#34;&gt;ovs-vsctl -- --id=@veth100i9 get port veth100i9 -- set mirror span output-port=@veth100i9&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that&amp;rsquo;s it. Log into your host and do a tcpdump on whatever interface is mapped to veth100i9 and you should see packets flowing. A few tips:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Verify your span from the hardware switch is working before diving into the software stack.&lt;/li&gt;
&lt;li&gt;If you&amp;rsquo;re doing this is proxmox, be aware that proxmox networking stack can be unforgiving when you much around outside of their environment.&lt;/li&gt;
&lt;li&gt;This will not persist across reboots. Add it to /etc/network/interfaces manually to keep it after a restart.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Brocade Vyatta Install and OpenFlow 1.3 on ICX 7450</title>
      <link>https://forwardingplane.net/post/brocade-vyatta-install-and-openflow-1-3-on-icx-7450/</link>
      <pubDate>Sat, 20 Jun 2015 16:06:03 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/brocade-vyatta-install-and-openflow-1-3-on-icx-7450/</guid>
      <description>

&lt;p&gt;I recently had a need to test OpenFlow on the brocade ICX 7450 for a fairly good sized, high visibility &lt;a href=&#34;http://scinet.supercomputing.org&#34;&gt;project&lt;/a&gt;. The basic goal is pretty simple, Layer2 path provisioning. Straightforward and fairly well supported in OpenFlow, even from the early days. To do this, the idea was to use a turnkey platform, that way there is one throat to choke if there are issues. I landed on the &lt;a href=&#34;http://www1.brocade.com/forms/jsp/vyatta-controller/download.jsp&#34;&gt;Brocade Vyatta controller&lt;/a&gt; (which is essentially ODL), and the ICX. Below is a rough account of getting this up and working to the point of testing. For the purposes of this I used BVC 1.3 and an ICX 7450. The docs for the BVC are actually pretty good if you read them. I found the google searching for the docs led to &lt;sup&gt;9&lt;/sup&gt;&amp;frasl;&lt;sub&gt;10&lt;/sub&gt; links to brocade being 404 errors. My guess is that they restructured their site and did not alias anything. Minor frustration since my guess is that most folks search using a search engine rather than going to the site and searching from there. The link to the configuration guide I used for the ICX is &lt;a href=&#34;http://www.brocade.com/content/brocade/en/backend-content/pdf-page.html?/content/dam/common/documents/content-types/configuration-guide/fastiron-08030-sdnguide.pdf&#34;&gt;here&lt;/a&gt;. Once I grabbed the software, which requires registration, I went on to try to build this on CentOS 6.6. After some hurdles that I didn&amp;rsquo;t expect, I went and actually read the doc for BVC and found that ubuntu is a requirement. Another minor annoyance, but surmountable pretty easily. Enterprise customers are probably not going to want to have a one-off from RHEL/CentOS even if I don&amp;rsquo;t have a strong preference either way. Now that the VM is up and running with just over the minimum requirements, time to log in and get to work. This is assuming you have the code actually on the server already.```
apt-get install -y unzip curl wget python-pip&lt;br /&gt;
curl -sL &lt;a href=&#34;https://deb.nodesource.com/setup&#34;&gt;https://deb.nodesource.com/setup&lt;/a&gt; | sudo bash -
sudo apt-get install -y nodejs
unzip -o bvc-1.3.0.zip -d /opt
unzip -o bvc-dependencies-1.3.0.zip -d /opt
unzip -o bvc-app-pathexplorer-packaging-1.2.0.zip -d /opt
cd /opt/bvc
./install&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-The output should look something like this```&#34; data-lang=&#34;The output should look something like this```&#34;&gt; root@bvc:/opt/bvc# ./install
 Brocade Vyatta Controller Installation

 Starting @ : 2015-06-17 15:31:15.564202

 Performing prerequisite check ...
 JDK Check ................................ \[ OK \]
 CPU Count Check: ......................... \[ OK \]
 Memory Size Check: ....................... \[ OK \]

 Running pre-install scripts ...

 Unpacking archives ....................... \[ OK \]

 Setting up karaf container ............... \[ OK \]

 Running controller pre-install scripts ...

 Configuring base features ................ \[ OK \]
 Start controller ......................... \[ OK \]
 Waiting for base initialization .......... \[ OK \]

 Configuring all features ................. \[ OK \]
 Adding Repositories ...................... \[ OK \]
 Adding Features .......................... \[ OK \]

 Running controller post install scripts ...

 Running install scripts ...


 Stopping NODEJS server 9000 .............. \[ OK \]
 Starting NODEJS server  .................. \[ OK \]
   Server @ http://10.42.44.20:9000/

 Install completed @ :  2015-06-17 15:32:26.464365&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Monitoring the connection to the controller from the controller can be accomplished by using the included tool: /opt/bvc/bin/taillog which operates just like you think, by tailing a log file. Checking for capability can be pretty easily accomplished by looking at the restconf modules:```
http://&lt;IP address&gt;:8181/restconf/modules&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-Now, for the ICX, I was under the impression that OpenFlow was in the base code. This is a true statement, however, I made a bad assumption that it was in _all_ code for that platform. Not so. After banging around and reading release notes as well as contacting my SE, I found that the code that it shipped with did _not_ support openflow, so I would need to upgrade it. _The ICX 7450 (and probably others) requires at least Version 08.0.30aa for OpenFlow support. Earlier versions will be lacking in the entire command hierarchy, even for older versions of OpenFlow._ **Brocade ICX 7450 configuration** From the console:```&#34; data-lang=&#34;Now, for the ICX, I was under the impression that OpenFlow was in the base code. This is a true statement, however, I made a bad assumption that it was in _all_ code for that platform. Not so. After banging around and reading release notes as well as contacting my SE, I found that the code that it shipped with did _not_ support openflow, so I would need to upgrade it. _The ICX 7450 (and probably others) requires at least Version 08.0.30aa for OpenFlow support. Earlier versions will be lacking in the entire command hierarchy, even for older versions of OpenFlow._ **Brocade ICX 7450 configuration** From the console:```&#34;&gt;ip address 10.42.44.30 255.255.255.224
no ip dhcp-client enable
ip default-gateway 10.42.44.1
ip dns server-address 10.42.2.2
clock timezone us central
clock summer-time
logging host 10.42.44.7
logging enable user-login
logging enable config-changed
ntp 
server 10.42.2.2

interface ethernet 1/1/1 
port-name port1

crypto key generate rsa modulus 2048
ip ssh  authentication-retries 5
ip ssh timeout 120 
ip ssh key-authentication yes
username buraglio enable
username buraglio privilege 0
username buraglio password brocade

openflow enable ofv130 
openflow controller 10.42.44.20
system-max openflow-flow-entries 3072&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Thoughts: OpenFlow wants to use SSL by default. When configuring this it failed in a way that is not intuitive &lt;em&gt;at all&lt;/em&gt;. To get it running quickly, you need to disable SSL, which I absolutely &lt;em&gt;do not&lt;/em&gt; recommended for anything production). If you see anything other than this, the OpenFlow connection isn&amp;rsquo;t working```
SSH@icx-of-test#sh openflow controller
Openflow controller information&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;controller-mode-tcp-ssl-ip-address-port-status&#34;&gt;Controller   Mode      TCP/SSL   IP-address        Port   Status&lt;/h2&gt;

&lt;p&gt;1  (Equal)   active    TCP       10.42.44.20     6653   OPENFLOW_ESTABLISHED&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-This command will make it talk to the BVC over unencrypted TCP:```&#34; data-lang=&#34;This command will make it talk to the BVC over unencrypted TCP:```&#34;&gt;openflow controller ip-address 10.42.44.20 no-ssl port 6653 &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To make this work over SSL requires pulling the certificates into the device from the controller. I am still working on this for consideration in a production environment. Path explorer has most of the interesting bits in it. &lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/06/BVC-4.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/06/BVC-4.png&#34; alt=&#34;BVC-4&#34; /&gt;&lt;/a&gt; Other handy commands:```
SSH@icx-of-test#sh openflow inter
  interface     Show interfaces where OpenFlow is enabled
  &lt;cr&gt;
SSH@icx-of-test#sh openflow interface&lt;/p&gt;

&lt;p&gt;Total number of Openflow interfaces: 2&lt;/p&gt;

&lt;p&gt;Port   Link   Speed Tag MAC            OF-portid   Name           Mode
1/1/1  Up     1G    No  cc4e.248b.4570 1           port1          Hybrid-Layer23
1/1/48 Down   None  No  cc4e.248b.459f 48          port48         Hybrid-Layer23&lt;/p&gt;

&lt;p&gt;```The topology explorer is pretty cool, lots of eye candy. &lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/06/BVC-1.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/06/BVC-1.png&#34; alt=&#34;BVC-1&#34; /&gt;&lt;/a&gt; Random Thoughts:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Restarting the BVC causes the topology to need to rebuild, as one would expect. The ICX took longer to show up in the controller than I expected. In fact, it never recovered until I intervened manually.&lt;/li&gt;
&lt;li&gt;The Brocade ICX randomly rebooted while attempting to scp the bootloader code. I never figured out why.&lt;/li&gt;
&lt;li&gt;The ICX stopped responding to SSH for some reason. The only way I could recover it was to reboot. Concerning from a management standpoint, but I suspect it was an anomaly.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the next post I&amp;rsquo;ll explore the actual provisioning and the SSL configuration.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Monitoring VMware ESXi with SNMP and Cacti</title>
      <link>https://forwardingplane.net/post/monitoring-vmware-esxi-with-snmp-and-cacti/</link>
      <pubDate>Mon, 19 Jan 2015 10:02:10 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/monitoring-vmware-esxi-with-snmp-and-cacti/</guid>
      <description>&lt;p&gt;VMWare is a powerful tool, and monitoring is a critical service. How does one monitor such an integral piece of infrastructure, and what do they monitor it with? There are powerful commercial ways of monitoring &lt;a href=&#34;http://www.vmware.com/&#34;&gt;VMware&lt;/a&gt;, however, for those with existing &lt;a href=&#34;http://en.wikipedia.org/wiki/Simple_Network_Management_Protocol&#34;&gt;SNMP&lt;/a&gt; based systems in place, specifically &lt;a href=&#34;http://www.cacti.net/&#34;&gt;cacti&lt;/a&gt;, there are options. To that end, I&amp;rsquo;ll set aside my strong distaste for SNMP [yet again], because those are for a larger, less useful series of posts.&lt;/p&gt;

&lt;p&gt;Luckily for those of us that need it there exists in that vast wilderness we call the internet, a user contributed &lt;a href=&#34;http://www.cacti.net/&#34;&gt;cacti&lt;/a&gt; template for monitoring basic functionality with SNMP and cacti and it is available &lt;a href=&#34;http://forums.cacti.net/download/file.php?id=29171&amp;amp;sid=888e5451bc68b1c05a5b7dec6667afd2&#34;&gt;here&lt;/a&gt;, and with the full thread being worth a read &lt;a href=&#34;http://forums.cacti.net/viewtopic.php?f=12&amp;amp;t=52122&#34;&gt;here&lt;/a&gt;. Since VMWare ESXi doesn&amp;rsquo;t have SNMP enabled (or really exposed from what I can tell), you have to do some CLI jockeying to make it work. Full disclosure, I&amp;rsquo;m not a vmware expert by any stretch of the imagination, but I have been hacking at it for a few years because it is low overhead to use comparatively speaking, offers a free version for my lab, makes a nice contrast to my KVM system and is widely deployed, so I want to understand it. Your mileage may vary with what I&amp;rsquo;ve got here.&lt;/p&gt;

&lt;p&gt;Enabling ssh is beyond the scope of this post but details can be found &lt;a href=&#34;http://www.thomasmaurer.ch/2014/01/enable-ssh-on-vmware-esxi-5-5/&#34;&gt;here&lt;/a&gt;. It&amp;rsquo;s fairly straightforward.&lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/01/vmware-snmp-device.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/01/vmware-snmp-device.png&#34; alt=&#34;vmware-snmp-device&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Details of enabling SNMP for vmware 5.5 can be found &lt;a href=&#34;https://pubs.vmware.com/vsphere-51/index.jsp#com.vmware.vsphere.monitoring.doc/GUID-0EB48A32-34B0-4003-B2D0-ADE3BAFD29F0.html&#34;&gt;here&lt;/a&gt;, essentially one simply needs to run the following commands from within an ssh session:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;esxcli  system snmp set --communities &amp;lt;community&amp;gt;
esxcli system snmp set --port 161
esxcli system snmp set --enable true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Getting the cacti scripts in place is a little more involved, but it&amp;rsquo;s still pretty simple. Using the importer just add the new template. &lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/01/Screenshot-2015-01-10-10.09.09.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/01/Screenshot-2015-01-10-10.09.09.png&#34; alt=&#34;Screenshot 2015-01-10 10.09.09&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; Once that is imported you&amp;rsquo;ll need to move some scripts into place within the cacti system as below (adjust your paths as needed; I moved them directly from my workstation into place)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scp ss\_esxi\_vhosts.php netmon:/var/lib/cacti/scripts/
scp cacte\_esxi\_template/resource/snmp\_queries/\* netmon:/usr/share/cacti/resource/snmp\_queries/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;[](&lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/01/Screenshot-2015-01-10-10.10.43.png)[![](http://www.forwardingplane.net/wp-content/uploads/2015/01/vmware-snmp-device.png)](http://www.forwardingplane.net/wp-content/uploads/2015/01/vmware-snmp-device.png&#34;&gt;http://www.forwardingplane.net/wp-content/uploads/2015/01/Screenshot-2015-01-10-10.10.43.png)[![](http://www.forwardingplane.net/wp-content/uploads/2015/01/vmware-snmp-device.png)](http://www.forwardingplane.net/wp-content/uploads/2015/01/vmware-snmp-device.png&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;[](&lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/01/Screenshot-2015-01-10-10.13.33.png&#34;&gt;http://www.forwardingplane.net/wp-content/uploads/2015/01/Screenshot-2015-01-10-10.13.33.png&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Then adjust the template being used for your ESXi server or add it as a new host if it was not there already. The new template should show up in the list.&lt;/p&gt;

&lt;p&gt;Once complete the cacti server should start graphing and checking uptime, etc. IF it does not, make sure the scripts are in place and have the correct permissions. It&amp;rsquo;s also useful (although not required) to add the additional parameters to the host.&lt;/p&gt;

&lt;p&gt;Once complete, the cacti system should be able to baseline (and alert if so desited, using thresholds) on any of the newly added variables, including number of VMs, number of VMs using vmware tools, number of VMs running, disk space, processes, network traffic, etc.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/01/vmware-create-graphs.png&#34; alt=&#34;vmware-create-graphs&#34; /&gt;  &lt;/p&gt;

&lt;p&gt;I have yet to be able to get successful CPU graphs, but I suspect it is user error on my part and I&amp;rsquo;ve not investigated yet. Overall, I&amp;rsquo;d call it a pretty bigwin for anyone that has an existing cacti installation and wants to include their vmware system(s). It should also be said that the readme that accompanies the template is relatively useful.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NIX4Neteng 4: POODLE and SSLv3, scanning and updating</title>
      <link>https://forwardingplane.net/post/nix4neteng-4-poodle-and-sslv3-scanning-and-updating/</link>
      <pubDate>Wed, 15 Oct 2014 17:36:54 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/nix4neteng-4-poodle-and-sslv3-scanning-and-updating/</guid>
      <description>&lt;p&gt;With the recent release of the &lt;a href=&#34;https://www.openssl.org/~bodo/ssl-poodle.pdf&#34;&gt;POODLE SSLv3 vulnerability&lt;/a&gt;, folks are scrambling around trying to figure out what runs what and where.  Running a handful of things that do SSL, I was obligated, both personally and professionally, to figure out an easy way to drill down and figure out what does what and then fix the vulnerable services.  When there are a lot of devices, this can seem like a daunting task, and it is if you&amp;rsquo;re trying to do it manually.  This is where &lt;a href=&#34;http://nmap.org/&#34;&gt;NMAP&lt;/a&gt; comes into play.  NMAP is an extremely powerful tool for scanning and enumerating your own network, not just a tool for the script kiddies to port scan. Since there is no SSL patch at the time of this writing, and since SSLv3 is old and depricated, it is a good idea to see what services support it and then squish them in favor of TLS 1+.  Thankfully, smarter folks than myself have done most of the legwork for accomplishing this task and written most of it down &lt;a href=&#34;http://nmap.org/nsedoc/scripts/ssl-enum-ciphers.html&#34;&gt;here&lt;/a&gt;. NMAP has a wealth of cool scripts and bolt ons that extend it in amazing ways.  To accomplish our tasks we&amp;rsquo;ll ned to do a few things. Install nmap. I ran into issues with the &lt;a href=&#34;http://nmap.org/book/nse-library.html&#34;&gt;nselibs&lt;/a&gt; being incomplete, so I grabbed the source and built it that way as opposed to using yum.```
git clone git@github.com:nmap/nmap.git&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-We then need to build it from source which requires the dev tools:```&#34; data-lang=&#34;We then need to build it from source which requires the dev tools:```&#34;&gt;sudo yum -y groupinstall &amp;#39;Development Tools&amp;#39;
cd nmap
./configure
sudo make&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and alternatively```
sudo make install&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-I like to just run it from my directory since there are path considerations.```&#34; data-lang=&#34;I like to just run it from my directory since there are path considerations.```&#34;&gt;(~/nmap) v-chimera $ ./nmap --script ssl-enum-ciphers -p 443 10.14.14.0/27

Starting Nmap 6.46 ( http://nmap.org ) at 2014-10-15 12:21 CDT
Nmap scan report for gw.test (10.14.14.1)
Host is up (0.0028s latency).
PORT    STATE  SERVICE
443/tcp closed https

Nmap scan report for ssldevice.test (10.14.14.2)
Host is up (0.0042s latency).
PORT    STATE SERVICE
443/tcp open  https
| ssl-enum-ciphers:
|   SSLv3:
|     ciphers:
|       TLS\_RSA\_WITH\_RC4\_128\_MD5 - strong
|       TLS\_RSA\_WITH\_RC4\_128\_SHA - strong
|     compressors:
|       NULL
|   TLSv1.0:
|     ciphers:
|       TLS\_RSA\_WITH\_RC4\_128\_MD5 - strong
|       TLS\_RSA\_WITH\_RC4\_128\_SHA - strong
|     compressors:
|       NULL
|\_  least strength: strong

Nmap scan report for nossl.test (10.14.14.3)
Host is up (0.00049s latency).
PORT    STATE  SERVICE
443/tcp closed https&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;From here we can see that there is a host that needs to be updated. There are a wealth of docs out there for changing out the supported version. Most of my stuff is apache so I used &lt;a href=&#34;https://zmap.io/sslv3/&#34;&gt;this guide&lt;/a&gt;. For embedded devices, the best option is to filter access [which you should probably be doing anyway] until there is a patched firmware version.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>sonrancid: A [very] basic RANCID module for sonicwall</title>
      <link>https://forwardingplane.net/post/sonrancid-a-very-basic-rancid-module-for-sonicwall/</link>
      <pubDate>Mon, 15 Sep 2014 09:05:13 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/sonrancid-a-very-basic-rancid-module-for-sonicwall/</guid>
      <description>&lt;p&gt;I know, I know, I&amp;rsquo;m always saying that you don&amp;rsquo;t need a firewall. That&amp;rsquo;s mostly to get your attention to push my agenda of sane security architecture, I do actually believe that firewalls are appropriate in a great many use cases and I&amp;rsquo;ve managed them big and small ranging from &lt;a href=&#34;http://www.forwardingplane.net/2010/08/juniper-srx-cluster/&#34; title=&#34;Juniper SRX Cluster&#34;&gt;Juniper SRX 5800 clusters&lt;/a&gt; to tiny purpose built BSD distros on custom hardware. I even managed &lt;a href=&#34;http://www.checkpoint.com/&#34;&gt;Checkpoint&lt;/a&gt; and &lt;a href=&#34;http://www.kulichki.com/moshkow/SECURITY/gauntlet.txt&#34;&gt;gauntlet firewall&lt;/a&gt; back in the 1990s. And &lt;a href=&#34;https://www.novell.com/products/bordermanager/&#34;&gt;Novell Border manager&lt;/a&gt;&amp;hellip;.good gravy&amp;hellip;.border manager. I just had a chill, that thing is still around.  They work well when spec&amp;rsquo;d, designed, maintained correctly and placed in an appropriate location in a network architecture.  That said, I have a few SonicWall devices that I work on occasionally and it has always irritated me that there was not a usable &lt;a href=&#34;http://www.shrubbery.net/rancid/&#34;&gt;RANCID&lt;/a&gt; module for it.  To that end, I hacked up the Cisco RANCID script to support very rudimentary config backups. &lt;em&gt;&lt;Insert comment about having some DevOps skills is useful, even if they are very basic like mine.&gt;&lt;/em&gt; The script will log in and pull the config and version using the following commands:&lt;code&gt;
show current-config
&lt;/code&gt;&lt;code&gt;
show version
&lt;/code&gt;I am really hoping that someone else will pick it up and massage it a bit because it is very chatty and will produce a diff every time due to the way SonicOS presents some of its configuration parameters. It also needs tested against larger SonicWall devices as I only have smaller boxes to run against.  I know it works against a TZ210, YMMV. Please post comments on github if you use it with anything else.   The password hash is particularly annoying, it always changes when the configuration is displayed. Some of the framework is there to remove it so I may hack at it a bit more but it&amp;rsquo;s usable in the loosest sense for the short term.  It&amp;rsquo;s available on &lt;a href=&#34;https://github.com/buraglio/sonrancid&#34;&gt;my github site&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NIX4NetEng 3: IP Addressing and Subnet Tools</title>
      <link>https://forwardingplane.net/post/nix4neteng-3-ip-addressing-and-subnet-tools/</link>
      <pubDate>Sat, 26 Jul 2014 16:46:07 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/nix4neteng-3-ip-addressing-and-subnet-tools/</guid>
      <description>&lt;p&gt;IP addressing and subnetting is a common interview subject. I assert that memorizing these things is useful for learning the concepts but ultimately futile in that it is time consuming and inefficient use of engineering time when tools can be utilized to accomplish the same goals in less time with fewer errors. Honestly, I gave up doing this kind of work manually around 10 years ago and have never regretted it, and in actuality, I&amp;rsquo;d probably struggle to do it at this point because it&amp;rsquo;s a repetitive process better suited by code. In the old days, subnetting IPv4 manually was a badge of honor (and one that I always hated), but I learned it because I needed to know it for cert tests and daily work. However, once I started doing IPv6 around 2001, it became clear that doing this kind of thing by hand was consuming more time than it needed to. Enter UNIX tools. HEX Hex isn&amp;rsquo;t really a tool as much as it&amp;rsquo;s a hack for your shell.  Remember the &lt;a href=&#34;http://www.forwardingplane.net/2014/04/nix4neteng-1-managing-dotfiles-pwn-the-unspoken-pain-of-unix-administration/&#34; title=&#34;NIX4NetEng #1 Managing dotfiles; pwn the unspoken pain of UNIX administration&#34;&gt;post on dotfiles&lt;/a&gt;? This is something that can go right into your .bashrc and allows for the quick and easy translation of decimal to hexidecimal, which is very useful for IPv6 dual stacking because [in my opinion] the appropriate addressing scheme is to match the last octet based on hex and not numerically. So, to do that one needs to be able to easily convert the last octet quickly and easily.  Adding this to your .bashrc will accomplish this:```
alias hex=&amp;lsquo;printf &amp;ldquo;%x\n&amp;rdquo;&amp;rsquo;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-Now, if you have an address of 10.143.27.199, you take the .199 you can utilize the shell alias to convert it to the hex equivalent.  For example: If you&#39;re using static addresses or dhcpv6 with static addressing, you can match the last octet properly.```&#34; data-lang=&#34;Now, if you have an address of 10.143.27.199, you take the .199 you can utilize the shell alias to convert it to the hex equivalent.  For example: If you&#39;re using static addresses or dhcpv6 with static addressing, you can match the last octet properly.```&#34;&gt;(~) desktop $ hex 199
c7&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you&amp;rsquo;re using static addresses or dhcpv6 with static addressing, you can match the last octet properly.```
10.143.27.&lt;sup&gt;199&lt;/sup&gt;&amp;frasl;&lt;sub&gt;27&lt;/sub&gt;
2001:DB8:1b::c7/120&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-There are more than this, but these are the tools I use almost daily. I generally use [sipcalc](http://www.routemeister.net/projects/sipcalc/) at this point since it does what I used to use [ipcalc](http://jodies.de/ipcalc) for and more.  For gathering and verifying information, this is a fantastic tool.```&#34; data-lang=&#34;There are more than this, but these are the tools I use almost daily. I generally use [sipcalc](http://www.routemeister.net/projects/sipcalc/) at this point since it does what I used to use [ipcalc](http://jodies.de/ipcalc) for and more.  For gathering and verifying information, this is a fantastic tool.```&#34;&gt;(~) desktop $ sipcalc 2001:DB8:1b::c7/120
-\[ipv6 : 2001:DB8:1b::c7/120\] - 0
``````
\[IPV6 INFO\]
Expanded Address - 2001:0db8:001b:0000:0000:0000:0000:00c7
Compressed address - 2001:db8:1b::c7
Subnet prefix (masked) - 2001:db8:1b:0:0:0:0:0/120
Address ID (masked) - 0:0:0:0:0:0:0:c7/120
Prefix address - ffff:ffff:ffff:ffff:ffff:ffff:ffff:ff00
Prefix length - 120
Address type - Aggregatable Global Unicast Addresses
Network range - 2001:0db8:001b:0000:0000:0000:0000:0000 -
 2001:0db8:001b:0000:0000:0000:0000:00ff -&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And for IPv4:&lt;code&gt;
(~) desktop $ sipcalc 10.143.27.199/27
-\[ipv4 : 10.143.27.199/27\] - 0
&lt;/code&gt;&lt;code&gt;
\[CIDR\]
Host address - 10.143.27.199
Host address (decimal) - 177150919
Host address (hex) - A8F1BC7
Network address - 10.143.27.192
Network mask - 255.255.255.224
Network mask (bits) - 27
Network mask (hex) - FFFFFFE0
Broadcast address - 10.143.27.223
Cisco wildcard - 0.0.0.31
Addresses in network - 32
Network range - 10.143.27.192 - 10.143.27.223
Usable range - 10.143.27.193 - 10.143.27.222
&lt;/code&gt;  Notable mention: Web tools are also useful and are becoming more prolific than the UNIX tools, but I will assume that you&amp;rsquo;re probably already loged into a UNIX system like a jump box or bastion host anyway and the tools are faster and thinner in that environment. That said, here are some useful web tools: &lt;a href=&#34;http://jodies.de/ipcalc&#34;&gt;ipcalc&lt;/a&gt; has the web interface to their tool. &lt;a href=&#34;http://www.gestioip.net/cgi-bin/subnet_calculator.cgi&#34;&gt;This site&lt;/a&gt; has a v4 and v6 calculator that works well and looks a lot like the output of sipcalc.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NIX4NetEng 1 Managing dotfiles; pwn the unspoken pain of UNIX administration</title>
      <link>https://forwardingplane.net/post/nix4neteng-1-managing-dotfiles-pwn-the-unspoken-pain-of-unix-administration/</link>
      <pubDate>Thu, 01 May 2014 02:58:20 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/nix4neteng-1-managing-dotfiles-pwn-the-unspoken-pain-of-unix-administration/</guid>
      <description>&lt;p&gt;Many network engineers are also tasked with maintaining systems that provide network services, those things that make the network easier to use such as DNS and DHCP or management systems that perform useful things like monitor the network, collect flow data or bestow access to the equipment by acting as &lt;a href=&#34;http://en.wikipedia.org/wiki/Bastion_host&#34;&gt;bastion&lt;/a&gt; or jump hosts.  In many instances, robust and high availability services run on UNIX, Linux or BSD systems for stability and reliability, so those that manage these systems need to be well versed system admins as well as whatever their other job functions are.  &lt;a href=&#34;http://packetpushers.net/are-certifications-tests-still-worth-your-resources-in-the-day-of-hybrid-it/&#34;&gt;Hybridization&lt;/a&gt;, if you will.  Nothing new, nothing unexpected.  However, one of the banes of these tasks is having a uniform shell environment across platforms and systems. Why create a customized environment with aliases, environmental variables and other personalized settings more than once? I have struggled with how to do this efficiently across desktop, server, jumphosts and other daily use systems for &lt;strong&gt;years&lt;/strong&gt;. Most of the important variables are controlled by dotfiles.   In what I am hoping is the start of a short series of &amp;ldquo;UNIX stuff for networking folks&amp;rdquo;, I will explain how I did this for myself. UNIX and Linux admins have been dealing with dotfiles forever. GitHub even has a &lt;a href=&#34;http://dotfiles.github.io/&#34;&gt;repo dedicated to&lt;/a&gt; it.  For my environment, I chose to go with &lt;a href=&#34;http://jim.github.io/briefcase/&#34;&gt;Briefcase&lt;/a&gt; and &lt;a href=&#34;http://www.bitbucket.com&#34;&gt;BitBucket&lt;/a&gt;.  Briefcase because it has mechanisms for stripping out sensitive information if needed and bitbucket because I can have private repos without paying money.  This can all certainly be done with local git repos or github and without briefcase. Briefcase is really straightforward to install, it&amp;rsquo;s just a ruby gem, so &lt;em&gt;gem install briefcase&lt;/em&gt; is all that is needed to get it on your machine&lt;em&gt;.&lt;/em&gt;  OSX has it by default.  On my machine I needed to to&lt;em&gt;sudo gem update —system&lt;/em&gt; before it would install.  Your mileage may vary&lt;em&gt;. &lt;/em&gt; Once it&amp;rsquo;s installed, just add your files.  I switched to bash, so I needed to import .bashrc and .bash_profile, but I wanted to make sure I had a backup just in case.```
mkdir -p tmp/dotfiles
mv .bashrc tmp/dotfiles/
mv .bash_profile tmp/dotfiles/&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;briefcase import ~/.bashrc
briefcase import ~/.bash\_profile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;briefcase git remote add origin git@repo.forwardingplane.net:buraglio/briefcase-dotfiles.git&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;briefcase git commit -am &amp;quot;Initial newhost commit&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;briefcase git checkout origin master&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-Obviously replace the remote repo address with your own repo destination.   You can now check the status:```&#34; data-lang=&#34;Obviously replace the remote repo address with your own repo destination.   You can now check the status:```&#34;&gt;briefcase sync&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This should output something like this:```
Synchronizing dotfiles between /Users/buraglio/.dotfiles and /Users/buraglio
Symlink verified: /Users/buraglio/.bash_profile -&amp;gt; /Users/buraglio/.dotfiles/bash_profile
Symlink verified: /Users/buraglio/.bashrc -&amp;gt; /Users/buraglio/.dotfiles/bashrc
Symlink verified: /Users/buraglio/.profile -&amp;gt; /Users/buraglio/.dotfiles/profile
Symlink verified: /Users/buraglio/.README.md -&amp;gt; /Users/buraglio/.dotfiles/README.md&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-Getting a new branch for an existing host was the biggest hurdle for me, I want a base .bashrc but may want different environment variables for mac and Linux.  I&#39;m not a git expert by any means, so there may be a better way to do this, but it works well for me. To branch a new host, it&#39;s pretty straightforward.  Briefcase is really just a wrapper for git, so prepending &#34;briefcase&#34; before the git commands seems to &#34;just work&#34; (as I learned by trial and error or making this work). On an existing Host:```&#34; data-lang=&#34;Getting a new branch for an existing host was the biggest hurdle for me, I want a base .bashrc but may want different environment variables for mac and Linux.  I&#39;m not a git expert by any means, so there may be a better way to do this, but it works well for me. To branch a new host, it&#39;s pretty straightforward.  Briefcase is really just a wrapper for git, so prepending &#34;briefcase&#34; before the git commands seems to &#34;just work&#34; (as I learned by trial and error or making this work). On an existing Host:```&#34;&gt;git clone git@your.repoaddress.net:username/reponame.git .dotfiles
mkdir -p tmp/dotfiles
mv .bashrc tmp/dotfiles/
mv .bash\_profile tmp/dotfiles/
briefcase sync
briefcase git branch \[newhost\]
briefcase git checkout \[newhost\]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&amp;hellip;Make changes&amp;hellip;&lt;code&gt;
briefcase git commit -am &amp;quot;Initial newhost commit&amp;quot;
&lt;/code&gt;briefcase git push origin [newhost] There you have it, easily backed up and distributed environment control.  I&amp;rsquo;m planning to add &lt;a href=&#34;http://joeyh.name/code/etckeeper/&#34;&gt;etckeeper&lt;/a&gt; to this process next.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BGP tools; troubleshooting and monitoring external routing in a nutshell</title>
      <link>https://forwardingplane.net/post/bgp-tools-troubleshooting-and-monitoring-external-routing-in-a-nutshell/</link>
      <pubDate>Fri, 21 Mar 2014 04:51:06 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/bgp-tools-troubleshooting-and-monitoring-external-routing-in-a-nutshell/</guid>
      <description>&lt;p&gt;Time to rewind from the new and shiny and get back to roots of networking. &lt;a href=&#34;http://en.wikipedia.org/wiki/Border_Gateway_Protocol&#34;&gt;BGP&lt;/a&gt; is one of those odd protocols that is foundational to the functioning of the internet but yet somewhat hard to get experience with.  Say what you will about this venerable protocol, it&amp;rsquo;s been here a while and it is not going anywhere any time soon. I&amp;rsquo;ve been doing BGP since around late 1999, and I completely fell into it by accident, having only the Cisco &lt;a href=&#34;http://www.amazon.com/Internet-Routing-Architectures-2nd-Edition/dp/157870233X&#34;&gt;Internet Routing Architectures&lt;/a&gt; book (which I literally read cover to cover) and the &lt;a href=&#34;http://www.amazon.com/IP-Routing-Protocols-OSPF-Cisco/dp/0130142484/ref=la_B001HCXUMA_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1395373752&amp;amp;sr=1-1&#34;&gt;Ulysses Black Routing Protocols Book&lt;/a&gt;  and whatever I could find on a random search engine to guide me, and that was only after having to learn on the CLI for the first 6-7 months. In actuality, that is how many of the folks of my vintage came into doing BGP. Someone needed to announce some routes that were allocated to them by an &lt;a href=&#34;https://www.arin.net/knowledge/rirs.html&#34;&gt;RIR&lt;/a&gt;, or bring up some multi-homing or whatever.  Whoever knew how to work on the border device (or was willing to touch arguably the most important device on the network) got to learn how to do it. In 15 years of configuring, monitoring, tweaking, tuning and generally just maintaining BGP across service provider, research, enterprise networks and in labs and test environments, here are the tools I had to find to either put out fires, prevent blazing flames or prove that there is/was no fire. Lets assume that you already have all of the appropriate prefix lists, policy options and route maps in place to filter correctly. You&amp;rsquo;re doing that, right? If not, go do that and then come back to this. It will make your life easier in the long run. All eBGP peerings should have inbound and outbound filters on them. No exceptions. Yes, it can be a pain to maintain but when someone leaks you a full table when you&amp;rsquo;re expecting directly connected, you&amp;rsquo;ll be glad that they&amp;rsquo;re there. See below about automating the filters programatically. Now on to the fun stuff. Look at what the router is sending and receiving.  You know what you&amp;rsquo;re announcing, right? Under Cisco IOS the appropriate commands to display this information will look like this:```
show ip bgp neighbor  received-routes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;show ip bgp neighbor  advertised-routes
```In JunOS it will look like this:```
show route rec protocol bgp &amp;lt;neighbor&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;show route adv protocol bgp &lt;neighbor&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-On an Alcatel-Lucent the command will look like this:```&#34; data-lang=&#34;On an Alcatel-Lucent the command will look like this:```&#34;&gt;show router bgp neighbor &amp;lt;neighbor&amp;gt; advertised-routes&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Brocade has their methods too, it is &lt;em&gt;relatively&lt;/em&gt; similar to IOS. One important thing to note, JunOS requires no difference in the show command for IPv6. IOS and ALU has an additional command to display IPv6 information. IOS-XR may be different still, but I cannot confirm or recall since I have not used it since late 2012 (additions welcome in the comments).  For IPv6 on Cisco IOS and ALU respectively:```
show ipv6 bgp neighbors &lt;neighbor&gt; received-routes | advertised-routes&lt;/p&gt;

&lt;p&gt;show router bgp neighbor &lt;neighbor&gt; advertised-routes ipv6&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-This will provide a view from the street, it will display exactly what your router knows. [Route servers ](http://www.traceroute.org/#Route%20Servers)/ [Looking Glass](http://www.bgp4.as/looking-glasses) --This is your basic  external view. Log in and see what other ASNs know about your routes.  Critically important during those &#34;something is on fire&#34; times mentioned above.  They are maintained by a myriad of entities and positioned all over the globe. [BGPmon](http://www.bgpmon.org) --A project by [Andree Toonk](https://twitter.com/atoonk). Allows for the automatic discovery and monitoring of prefixes, alerting on many, many  attributes such as prefix hijacks.  Free and commercial plans available, but the commercial plans are far more feature rich and well worth it if you monitor large amounts og BGP. [Peermon](https://www.bgpmon.net/new-version-of-bgpmon-net/) --Part of the new and improved BGPmon.  Allows for the on-demand monitoring of prefixes within your network. Very useful for viewing as-path changes of destination networks for long term troubleshooting. [RouteViews](http://www.routeviews.org) -- Great project out of U of Oregon that was (is?) run by the groundbreaking [David Meyer](https://twitter.com/dmm613) of [OpenDaylight](http://www.opendaylight.org/) (and many other things) fame.  Peers with networks and records routing changes, allows for public query and has vast historical data. [bgplay](http://bgplay.routeviews.org/) - Great visualization tool for tracking routing, as-path and prefix announcement changes. This is part of the routeviews project and utilizes their vast historical data.  L=It currently acks IPv6 support and I;m unsure if it is maintained anymore. [Router Proxies](http://routerproxy.grnoc.iu.edu/internet2/) -- This has been a big thing int he R&amp;E world for quite some time.  Other entities may offer it, it&#39;s similar to a looking glass but more easily configured to allow or disallow different show commands.  The [code is open source](http://routerproxy.sourceforge.net/) and pretty easy to hack new commands into or adapt to new platforms (if I can do it anyone can). Lookup tools such as whois.  I find that looking uo ASNs and networks against the ARIN, RIPE and other RIRs is very handy as a starting point.  using CLI commands such as &#34;whois -h whois.arin.net 1224&#34; would display the following information:```&#34; data-lang=&#34;This will provide a view from the street, it will display exactly what your router knows. [Route servers ](http://www.traceroute.org/#Route%20Servers)/ [Looking Glass](http://www.bgp4.as/looking-glasses) --This is your basic  external view. Log in and see what other ASNs know about your routes.  Critically important during those &#34;something is on fire&#34; times mentioned above.  They are maintained by a myriad of entities and positioned all over the globe. [BGPmon](http://www.bgpmon.org) --A project by [Andree Toonk](https://twitter.com/atoonk). Allows for the automatic discovery and monitoring of prefixes, alerting on many, many  attributes such as prefix hijacks.  Free and commercial plans available, but the commercial plans are far more feature rich and well worth it if you monitor large amounts og BGP. [Peermon](https://www.bgpmon.net/new-version-of-bgpmon-net/) --Part of the new and improved BGPmon.  Allows for the on-demand monitoring of prefixes within your network. Very useful for viewing as-path changes of destination networks for long term troubleshooting. [RouteViews](http://www.routeviews.org) -- Great project out of U of Oregon that was (is?) run by the groundbreaking [David Meyer](https://twitter.com/dmm613) of [OpenDaylight](http://www.opendaylight.org/) (and many other things) fame.  Peers with networks and records routing changes, allows for public query and has vast historical data. [bgplay](http://bgplay.routeviews.org/) - Great visualization tool for tracking routing, as-path and prefix announcement changes. This is part of the routeviews project and utilizes their vast historical data.  L=It currently acks IPv6 support and I;m unsure if it is maintained anymore. [Router Proxies](http://routerproxy.grnoc.iu.edu/internet2/) -- This has been a big thing int he R&amp;E world for quite some time.  Other entities may offer it, it&#39;s similar to a looking glass but more easily configured to allow or disallow different show commands.  The [code is open source](http://routerproxy.sourceforge.net/) and pretty easy to hack new commands into or adapt to new platforms (if I can do it anyone can). Lookup tools such as whois.  I find that looking uo ASNs and networks against the ARIN, RIPE and other RIRs is very handy as a starting point.  using CLI commands such as &#34;whois -h whois.arin.net 1224&#34; would display the following information:```&#34;&gt;#
# The following results may also be obtained via:
# http://whois.arin.net/rest/asns;q=1224?showDetails=true&amp;amp;ext=netref2
#
``````
ASNumber: 1224
ASName: NCSA-AS
ASHandle: AS1224
RegDate: 1991-02-25
Updated: 1997-10-27
Ref: http://whois.arin.net/rest/asn/AS1224
``````
OrgName: National Center for Supercomputing Applications
OrgId: NCSA-3
Address: NCSA
Address: 1205 W. Clark St
City: Urbana
StateProv: IL
PostalCode: 61801
Country: US
RegDate: 1990-03-26
Updated: 2011-04-06
Ref: http://whois.arin.net/rest/org/NCSA-3
``````
OrgAbuseHandle: ND63-ORG-ARIN
OrgAbuseName: Network Development
OrgAbusePhone: +1-217-244-0714
OrgAbuseEmail: neteng @ ncsa.illinois.edu
OrgAbuseRef: http://whois.arin.net/rest/poc/ND63-ORG-ARIN
``````
OrgTechHandle: ND63-ORG-ARIN
OrgTechName: Network Development
OrgTechPhone: +1-217-244-0714
OrgTechEmail: neteng @ ncsa.illinois.edu
OrgTechRef: http://whois.arin.net/rest/poc/ND63-ORG-ARIN
``````
RTechHandle: ND63-ORG-ARIN
RTechName: Network Development
RTechPhone: +1-217-244-0714
RTechEmail: neteng @ ncsa.illinois.edu
RTechRef: http://whois.arin.net/rest/poc/ND63-ORG-ARIN
``````
#
# ARIN WHOIS data and services are subject to the Terms of Use
# available at: https://www.arin.net/whois\_tou.html
#&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Very handy for prefixes and ASNs.  There are also service like the &lt;a href=&#34;https://www.team-cymru.org/Services/ip-to-asn.html&#34;&gt;Team Cymru whois server&lt;/a&gt; that can display date/time based information for forensics and to provide IP to ASN mappings. Also very handy.  I believe this code is also open source. &lt;a href=&#34;http://irrtoolset.isc.org/&#34;&gt;IRR Toolset&lt;/a&gt;.  Extremely handy for automation of routing policy configuration.  I found it a tad painful to set up but it is a useful toolkit. Notable Mention: &lt;a href=&#34;https://ring.nlnog.net/&#34;&gt;NLNog RING&lt;/a&gt;.  &amp;ndash; This is a trust based unix host that provides a &lt;a href=&#34;https://ring.nlnog.net/toolbox/&#34;&gt;large variety of services&lt;/a&gt; to those that qualify for participation.  Very handy when looking for an on-net perspective. Notable Mention / Shameless Plug: &lt;a href=&#34;http://psps.perfsonar.net/toolkit/&#34;&gt;perfSonar toolkit&lt;/a&gt;.  In addition to thewell known performance testing tools, PS provides things like reverse traceroute and other handy networking widgets.  It also has a far lower barrier of entry than the NLNog RING.   There are obviously more ways to do this and there are possibly better ones, too.  This is how I&amp;rsquo;ve done it for a long time and it has mostly worked for me.  I had to learn most of this by trial and error so I thought it maybe useful to throw it all together into one place for future reference.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Replace ZFS RAIDZ1 disk</title>
      <link>https://forwardingplane.net/post/replace-zfs-raidz1-disk/</link>
      <pubDate>Tue, 11 Mar 2014 01:01:58 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/replace-zfs-raidz1-disk/</guid>
      <description>&lt;p&gt;I recently had the displeasure of dealing with a series of failed disks in my newly created ZFS based NAS.  I had cobbled together roughly 12TB of disk space and jammed them into an old PC, stretching the limits of the platform when I decided to go with ZFS.  I broke all of the rules, underpowered, single core PC, only a handful of GIG of non-ECC RAM, etc.  I&amp;rsquo;m sure storage guys are having a coronary after reading that, but it works for me and has minimal issues since I just relatively redundant need bulk storage and it doesn&amp;rsquo;t need to be fast (the ethernet connection is only 100M). Machine stats are as such: AMD Sempron&amp;trade; Processor 2800+ 2G NON-ECC memory The following disks:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2014/03/Screenshot-2014-03-10-13.49.35.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2014/03/Screenshot-2014-03-10-13.49.35-1024x280.png&#34; alt=&#34;Screenshot 2014-03-10 13.49.35&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The NAS was a long standing device on my network.  I&amp;rsquo;ve been using &lt;a href=&#34;http://www.nas4free.org/&#34;&gt;NAS4FREE&lt;/a&gt; for quite some time with fantastic results.  The disks are simply desktop drives, nothing fancy.  When I rebuilt it all using ZFS I found that I had not done 2 things.  I had not documented the warranty status of the devices and I had not enabled SMART monitoring.  I know, amateur hour at its finest; I&amp;rsquo;m OK with it, it&amp;rsquo;s just for home use and I have offsite storage for anything super important. *&lt;em&gt;As an aside, if you&amp;rsquo;re looking to build a NAS I would both recommend &lt;a href=&#34;http://www.nas4free.org/&#34;&gt;NAS4FREE&lt;/a&gt; as well as doing something as simple as documenting the warranty information of each disk in the description field.&lt;/em&gt; So, when I enabled SMART monitoring and email reporting. I found that several of my disks were failing their end-to-end tests when this started showing up in my inbox:  ```
The following warning/error was logged by the smartd daemon:
Device: /dev/ada1, Failed SMART usage Attribute: 184 End-to-End_Error.
Device info:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ST2000DM001-1CH164, S/N:xxxxxxxx, WWN:5-000c50-08147e2a4, FW:CC26, 2.00 TB
```  Bad news. However, with ZFS it is supposed to be fantastically easy to do disk replacements.  I had chosen RAIDZ1 for both volumes, so they could each supposedly sustain a single disk failure. There are a lot of online references for zfs. I used [this page](http://panoramicsolution.com/blog/?p=353) as a starting point for replacing my disk. I dropped to the shell on the NAS and did the following to identify the right disk to remove:```
nas:~# camcontrol devlist
&amp;lt;ST31000340AS SD15&amp;gt; at scbus0 target 0 lun 0 (ada0,pass0)
&amp;lt;ST2000DM001-1CH164 CC26&amp;gt; at scbus1 target 0 lun 0 (ada1,pass1)
&amp;lt;ST2000DM001-1CH164 CC24&amp;gt; at scbus2 target 0 lun 0 (ada2,pass2)
&amp;lt;ST2000DM001-1CH164 CC26&amp;gt; at scbus3 target 0 lun 0 (ada3,pass3)
&amp;lt;WDC WD20EARS-00MVWB0 51.0AB51&amp;gt; at scbus4 target 0 lun 0 (ada4,pass4)
&amp;lt;ST31500341AS CC1H&amp;gt; at scbus5 target 0 lun 0 (ada5,pass5)
&amp;lt;ST2000DM001-1CH164 CC29&amp;gt; at scbus6 target 0 lun 0 (ada6,pass6)
&amp;lt;ST31500341AS CC1H&amp;gt; at scbus7 target 0 lun 0 (ada7,pass7)
&amp;lt;ST2000DM001-9YN164 CC82&amp;gt; at scbus8 target 0 lun 0 (ada8,pass8)
&amp;lt;TOSHIBA THNCF512MPG 1.00&amp;gt; at scbus11 target 0 lun 0 (ada9,pass9)
```ada8 needs replaced.  The volume it exists in is zfs0.  The formula used is _&amp;quot;zpool &amp;lt;command&amp;gt; &amp;lt;pool&amp;gt; &amp;lt;device&amp;gt;&amp;quot;_```
zpool offline zfs0 ada8
```None of my stuff is hot swap, so I have to shut down the box.```
shutdown -h now
```Yank out the old disk and install the new one.```
zpool replace zfs0 ada8
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;zpool online zfs0 ada8&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-After that you&#39;ll see the disk getting resilvered, which will take a while.```&#34; data-lang=&#34;After that you&#39;ll see the disk getting resilvered, which will take a while.```&#34;&gt;nas:~# zpool status zfs0
pool: zfs0
state: DEGRADED
status: One or more devices is currently being resilvered. The pool will
continue to function, possibly in a degraded state.
action: Wait for the resilver to complete.
scan: resilver in progress since Mon Mar 10 13:39:36 2014
105G scanned out of 3.37T at 75.4M/s, 12h36m to go
17.5G resilvered, 3.04% done
config:

NAME STATE READ WRITE CKSUM
zfs0 DEGRADED 0 0 0
raidz1-0 DEGRADED 0 0 0
ada1 ONLINE 0 0 0
ada2 ONLINE 0 0 0
ada3 ONLINE 0 0 0
ada4 ONLINE 0 0 0
ada6 ONLINE 0 0 0
replacing-5 OFFLINE 0 0 0
6070465578770542405 OFFLINE 0 0 0 was /dev/ada8/old
ada8 ONLINE 0 0 0 (resilvering)

errors: No known data errors&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After the resilvering process you should have a repaired volume.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
