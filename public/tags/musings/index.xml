<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>
    Musings on ForwardingPlane.net
    
    </title>
    <link>https://forwardingplane.net/tags/musings/</link>
    <description>Recent content 
    
    in Musings on ForwardingPlane.net
    </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
    
    <copyright>Copyright (c) 2019, all rights reserved.</copyright>
    <lastBuildDate>Sat, 02 Nov 2019 18:11:58 +0000</lastBuildDate>
    
    
        <atom:link href="https://forwardingplane.net/tags/musings/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Packet Pushers Weekend Edition Number 1</title>
      <link>https://forwardingplane.net/post/packet-pushers-weekend-edition-no1/</link>
      <pubDate>Sat, 02 Nov 2019 18:11:58 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/packet-pushers-weekend-edition-no1/</guid>
      <description>&lt;p&gt;We all know the &lt;a href=&#34;https://www.packetpushers.net&#34;&gt;Packet Pushers&lt;/a&gt;. Recently, I had the pleasure of sitting in on the inagural &lt;a href=&#34;https://www.youtube.com/watch?v=goQ9ppGwrEo&amp;amp;t=1668s&#34;&gt;&amp;ldquo;Packet Pushers Weekend Edition&amp;rdquo;&lt;/a&gt; - an informal, video round table where we discuss fun and relevant topics in the space of networking and other related IT topics. Much discussion was had on SR-MPLS, Service providers, SD-WAN, and Cloud. I hope to participate again, as I found the experience both entertaining and informative, I hope you will too.&lt;/p&gt;

&lt;p&gt;Tune in here:&lt;/p&gt;

&lt;iframe width=&#34;560&#34; height=&#34;315&#34; src=&#34;https://www.youtube.com/embed/goQ9ppGwrEo&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
</description>
    </item>
    
    <item>
      <title>ElastiFlow Template VM</title>
      <link>https://forwardingplane.net/post/elastiflow-template-vm/</link>
      <pubDate>Sun, 08 Sep 2019 18:11:58 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/elastiflow-template-vm/</guid>
      <description>&lt;p&gt;Flow data is a critical piece of understanding how your network works what what it is actively doing. It also provides a great baseline and capacity planning tool. However, some of the more feature rich NetFlow and/or sFlow collectors can be quite daunting in their cost and/or complexity to install. &lt;a href=&#34;https://github.com/robcowart/elastiflow&#34;&gt;ElastiFlow&lt;/a&gt; is a great alternative for flow analytics and is built on the well traveled and robust &lt;a href=&#34;https://www.elastic.co/start?ultron=[EL]-[B]-[AMER]-US+CA-Exact&amp;amp;blade=adwords-s&amp;amp;Device=c&amp;amp;thor=elastic%20stack&amp;amp;gclid=EAIaIQobChMIuKC5xefB5AIVCYnICh0wEg5lEAAYASAAEgIp_fD_BwE&#34;&gt;ElasticStack&lt;/a&gt;, meaning, its back end is well documented, well supported, and scales exceptionally well. For those that would like to play around with this but don&amp;rsquo;t want to take the time to install it (see below for the instruction set I used), I have provided a simple VM to toy around with.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2019/09/Screen-Shot-2019-09-07-at-11.00.35-PM-1024x704.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Included here is a vanilla Ubuntu 18 LTS VM with a basic &lt;a href=&#34;https://github.com/robcowart/elastiflow&#34;&gt;Elastiflow&lt;/a&gt; install. This includes all of the components of an ElasticStack plus the front end pieces of the ElastiFlow project. Most of the install is based on &lt;a href=&#34;https://www.catapultsystems.com/blogs/install-elastiflow-on-ubuntu-18-04-part-1/&#34;&gt;this&lt;/a&gt; how-to. &lt;/p&gt;

&lt;p&gt;Included in the image is also a base install of NGINX and certbot so that you can reverse proxy the access and have a valid SSL certificate. There are a plethora of guides on how to accomplish that task on the internet.&lt;/p&gt;

&lt;p&gt;This was build and validated on Proxmox 6.0.6 but should be able to run on VMWare as well with a bit of qemu-img conversion. As expected, ElastiFlow (and ElasticStack) are fairly resource hungry. 16G of Memory and a handful of CPU cores is the bare minimum to run this with any real efficiency. Additionally, Ubuntu 18 has changed how the networking is setup - it is all located in /etc/netplan/ now.   &lt;/p&gt;

&lt;p&gt;Login Information:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;User Name: root
Password: elastiflow
Privileged user: elastiflow
Password: elastiflow  

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Default IP addresses:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;10.255.255.5/27
2001:db8:ffff:2::5/64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Download the image &lt;a href=&#34;https://drive.google.com/open?id=1ga_Pj2j6h1ce9rcT7jQjncpVjLIC4X4t&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The BGP conundrum</title>
      <link>https://forwardingplane.net/post/the-bgp-conundrum/</link>
      <pubDate>Sun, 30 Jun 2019 02:15:32 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/the-bgp-conundrum/</guid>
      <description>&lt;p&gt;BGP. It’s that magical protocol that runs the internet. For for as much as BGP is a fundamental, critical, irreplaceable part of the core functioning of the internet, it is a protocol that has not aged well as far as security is concerned. See, BGP was born when the internet was really still an academic experiment. Handshakes and loose agreements were totally fine for connecting a new site. &lt;/p&gt;

&lt;p&gt;Then came the awakening. &lt;img src=&#34;https://www.forwardingplane.net/wp-content/uploads/2019/06/Awakening.jpg&#34; alt=&#34;Awakening&#34; title=&#34;Awakening.jpg&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Once the internet was used for more critical things, security was obviously more important. But BGP did not really evolve at the same rate - and more importantly, the security model surrounding it was mostly left behind. The reasons aren&amp;rsquo;t really important, but the fallout absolutely is. Retrofitting security into an externally exposed protocol is demonstrably difficult. It has been &lt;a href=&#34;https://tools.ietf.org/html/rfc8205&#34;&gt;tried&lt;/a&gt; and &lt;a href=&#34;https://tools.ietf.org/html/rfc6810&#34;&gt;tried&lt;/a&gt; and &lt;a href=&#34;https://tools.ietf.org/id/draft-sa-grow-maxprefix-00.html&#34;&gt;tried&lt;/a&gt; and &lt;a href=&#34;https://www.radb.net/&#34;&gt;tried&lt;/a&gt;. The real limit in this space exists because of the nature of the protocol itself - it is external in nature, thereby requiring coordination between multiple parties. The mechanics of this are two fold: personal interaction to agree on the peering, and technical compliance for the protocol to adhere to the agreed upon policy.&lt;/p&gt;

&lt;p&gt;Technical limitations imposed by vendors and hardware limits have plagued this space for decades. However, the real problem, as with most things technical, is actually the people. A reluctance to agree on methodology, a refusal to spend the time to work out the procedures, an inability or lack of resources for understanding the steps necessary, an unwillingness (intentional or unintentional) to help the community further the progress. None of this really matters other than knowing where we can improve. So, to that end, I humbly recommend that all BGP operators read and implement best practices. Much of this is spelled out clearly in the &lt;a href=&#34;https://www.manrs.org/isps/&#34;&gt;MANRS project&lt;/a&gt;, and it should be used as a shining example of community based action that can produce actual demonstrable results. If you’re interested in tools for troubleshooting BGP or better understanding the scope and scale of the DFZ (Default Free Zone), check out a past post I did on &lt;a href=&#34;https://www.forwardingplane.net/2014/03/bgp-tools-troubleshooting-and-monitoring-external-routing-in-a-nutshell/&#34;&gt;BGP tools,&lt;/a&gt; &lt;a href=&#34;https://www.forwardingplane.net/2016/05/bgp-rpki-why-arent-we-using-it/&#34;&gt;RPKI&lt;/a&gt;, and &lt;a href=&#34;https://www.forwardingplane.net/2018/02/strategy-series-view-outside-network/&#34;&gt;visibility outside of your network.&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;As a follow on to the last global BGP blunder, &lt;a href=&#34;https://twitter.com/bcjordo?lang=en&#34;&gt;Jordan Martin&lt;/a&gt; and I talk about the how and the what of the event in this quick &lt;a href=&#34;https://thenetworkcollective.com/2019/06/bgp-blunder/&#34;&gt;Network Collective short take&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rant: toolexplodeaphobia</title>
      <link>https://forwardingplane.net/post/1672/</link>
      <pubDate>Fri, 03 May 2019 13:58:55 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/1672/</guid>
      <description>&lt;p&gt;It’s kinda like having RouteExplorer and Arbor Peakflow. They have a decent overlap but *just* enough difference to want both&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DNS - the treasure trove of information your ISP can see</title>
      <link>https://forwardingplane.net/post/dns-the-treasure-trove-of-information-your-isp-can-see/</link>
      <pubDate>Mon, 10 Dec 2018 10:23:42 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/dns-the-treasure-trove-of-information-your-isp-can-see/</guid>
      <description>&lt;p&gt;In recent years, the nature of &lt;a href=&#34;http://fortune.com/2017/11/23/net-neutrality-explained-what-it-means-and-why-it-matters/&#34;&gt;privacy on the internet&lt;/a&gt; has become a very important topic amongst those concerned with the now lack of &lt;a href=&#34;https://www.theverge.com/2017/12/14/16776154/fcc-net-neutrality-vote-results-rules-repealed&#34;&gt;net neutrality&lt;/a&gt;. The de-facto mechanism for dealing with privacy has been to &amp;ldquo;&lt;a href=&#34;https://letsencrypt.org/&#34;&gt;SSL all the things&lt;/a&gt;&amp;rdquo;, which I am very much in favor of. What many do not realize, though, is that simply using SSL for the traffic that transits a given ISP still leaves a wealth of thick, rich, delicious personal data still easily available to your ISP to harvest, sell, and do with as they please. This data comes in the form of DNS queries. DNS is the nearly-always-forgotten, crucial aspect of how the internet functions. Without DNS, nothing works. Everything appears broken and manifest as what appears to be a networking problem. ISPs typically provide what is called a &lt;a href=&#34;https://umbrella.cisco.com/blog/2014/07/16/difference-authoritative-recursive-dns-nameservers/&#34;&gt;recursive resolver&lt;/a&gt;, which for most people is handed down by a local provider to the customer premise equipment (CPE; usually a modem or optical terminal of some kind) that they install at a residence. This CPE then hands that resolver to your clients that use it to - you guessed it - recursively resolve DNS queries. These queries can be logged and then mined for browsing habits, etc. Anyone that has ever done any network forensics will know straight away that the value of the information contained in DNS query logs is very, very high. &lt;/p&gt;

&lt;p&gt;What this means is that even though a privacy conscious individual is hiding the bulk of their content in SSL, meaning the bulk of what they’re reading, searching for, and doing, is encrypted, the requests for that content or activity is not. For example, an ISP can potentially see that a client is making many, many queries for $onlineshopping.com and begin selling that data to advertisers. If you think they’re not doing this now, &lt;a href=&#34;https://www.wired.com/story/can-verizon-build-a-strong-brand-from-the-bones-of-yahoo-and-aol/&#34;&gt;think again&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Great, so $bigbadprovider can see your queries. There are a number of pretty good ways to work around this, and &lt;a href=&#34;https://pi-hole.net/&#34;&gt;one of my favorite projects&lt;/a&gt; handily deals with one of them with great simplicity. What I am referring to is the newly popular &lt;a href=&#34;https://scotthelme.co.uk/securing-dns-across-all-of-my-devices-with-pihole-dns-over-https-1-1-1-1/&#34;&gt;DNS over HTTPS&lt;/a&gt;, which is supported by the &lt;a href=&#34;https://one.one.one.one/&#34;&gt;cloudflare 1.1.1.1 service&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;So, as a thought experiment I decided to play Reeses Peanut butter and chocolate with two of my favorite technological creations: the aforementioned PiHole, and &lt;a href=&#34;https://zerotier.com/&#34;&gt;ZeroTier&lt;/a&gt;. Now anyone that isn’t familiar with ZeroTier, you should acquaint yourself - Packet Pushers did a good &lt;a href=&#34;https://packetpushers.net/podcast/pq-134-meet-zerotier-open-source-networking/&#34;&gt;podcast on it back in November of 2017&lt;/a&gt;. It’s functionally an encrypted overlay supporting dual stack networking with auto configuration and gateway capabilities, and it runs on almost everything. I love this overlay technology and have been using it for a while - highly recommended.&lt;/p&gt;

&lt;p&gt;Back to my peanut butter and chocolate experiment. So, given that I had an existing ZeroTier network and an existing PiHole setup at home, I went over to &lt;a href=&#34;https://www.vultr.com/?ref=7692870&#34;&gt;Vultr.com&lt;/a&gt; and spun up a small VM for $3.50/mo, integrated it into my fleet with my Ansible and Salt tools, and installed ZeroTier and Pihole. From there I set up this DNS hierarchy. &lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://docs.google.com/drawings/d/e/2PACX-1vS-DsmzNWvE335KZtNo6AHX3SySG-VQWhK7i9sNgT6mFMHC5VzRWtMuJg5JraU2dJTFQT4QIGnfaMFP/pub?w=960&amp;amp;h=720&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What this buys me is a fully encrypted DNS path up through the Vultr.com VM host without modifying the underlying DNS transport. And it works surprisingly well. I ran SmokePing from two hosts - both leveraging ZeroTier to do their testing, one on my local network and one in the cloud - to measure latency for a few days before I did this and kept that running after the deployment. Now, it’s not perfect but my family and I have been using this for about a month with minimal issues. Once in a great while we’ll see some slow DNS resolution time, but overall it works fairly well. &lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.forwardingplane.net/wp-content/uploads/2018/12/Resolver-Queries.png&#34; alt=&#34;Resolver Queries&#34; title=&#34;Resolver Queries.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;My take &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The idea of using a public resolver kinda bothers me, I realize it’s probably unfounded, but I know how to and have run resolvers for ISPs and organizations for like 20 years, so I have the burden of knowledge about what is in the logs and how to run my own. Using a secured recursive resolver is simply trading transit privacy for lack of query privacy somewhere else. Then there is the issue of content networks that use DNS queries to take you to the best / topologically closest cache of their content [NOTE: this, along with the forensics data for debugging potential security issues is a &lt;strong&gt;top&lt;/strong&gt; reason that all ISPs should run their own resolvers]. I fully realize that a normal end user running their own resolver is unlikely and that this deployment is a bit overkill. However, as I can demonstrably prove, it works. And it works pretty well. It also has the added bonus of allowing me to have internal DNS resolution of my own hosts and any mobile ZeroTier client. Is it for everyone? No way. Does it prove viability for low/medium traffic use? Sure. The point is really just to get folks thinking about information leaking that they may not have considered. The nature of the internet makes true privacy pretty much impossible, but there are a few ways to make your data a little harder to for companies to compile and capitalize on if you truly don’t want them to.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The rush to automation and the IT pendulum</title>
      <link>https://forwardingplane.net/post/the-rush-to-automation-and-the-it-pendulum/</link>
      <pubDate>Thu, 18 Oct 2018 14:20:52 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/the-rush-to-automation-and-the-it-pendulum/</guid>
      <description>

&lt;p&gt;Recently, the venerable &lt;a href=&#34;https://blog.ipspace.net&#34;&gt;Ivan Pepelnjak&lt;/a&gt; published a very insightful article about &lt;a href=&#34;https://blog.ipspace.net/2018/10/why-is-network-automation-such-hot-topic.html&#34;&gt;automation becoming such a popular topic&lt;/a&gt; that was spawned by an email from one of his readers. I found this article to be spot on, and wanted to add a bit of my own opinion into the automation pie, as I have been spending a lot of time on automation as it related to existing networks as well as into SDN based environments. There is a link, and I wanted to explore it a bit more whilst adding a healthy dose of my opinion. A very large part of the automation push is the IT pendulum swing. Like those of us that worked in the burgeoning ISP world, automating was born of necessity. Except - we didn&amp;rsquo;t call it automation. Most of us didn&amp;rsquo;t call it anything, it was sysadmin scripting at worst and full blown orchestration at best. And there were even commercial platforms (see broadband provisioning tools). However, like many of us that were in the early ISP days, at the very least we had some rudimentary programming and scripting skills because we either had to develop them to stay afloat or we came from an early applied computer science background. Those skills, like a lot of other things, also have the pendulum swing.&lt;/p&gt;

&lt;h2 id=&#34;https-media-giphy-com-media-tttkr0wqcuct2-giphy-gif&#34;&gt;&lt;img src=&#34;https://media.giphy.com/media/ttTKR0wqCUCt2/giphy.gif&#34; alt=&#34;&#34; /&gt;&lt;/h2&gt;

&lt;h2 id=&#34;the-pendulum&#34;&gt;The pendulum.&lt;/h2&gt;

&lt;p&gt;Think of the pendulum in terms of computing, as it&amp;rsquo;s the easiest to quantify. Computing went from centralized (i.e. the mainframe) to decentralized (i.e. the desktop PC). Now we&amp;rsquo;re moving back into the &amp;ldquo;centralized&amp;rdquo; model in the push to cloud (ok, that may be a tad different, but conceptually it&amp;rsquo;s the same - work with me). Moving computationally expensive operations out of a single, personal system into a larger resource while reducing the overhead of the end station. Think &lt;a href=&#34;https://www.amazon.com/Google-Pixelbook-RAM-128GB-GA00122-US/dp/B075JSK7TR/ref=sr_1_4_acs_osp_osp19-42c2a08e-2d_2?s=pc&amp;amp;ie=UTF8&amp;amp;qid=1539871559&amp;amp;sr=1-4-acs&amp;amp;keywords=chromebook&amp;amp;tag=crverifiedexp-20&amp;amp;ascsubtag=42c2a08e-2d48-4a89-8acb-841bc830f277&amp;amp;linkCode=oas&amp;amp;cv_ct_id=amzn1.osp.42c2a08e-2d48-4a89-8acb-841bc830f277&amp;amp;cv_ct_pg=search&amp;amp;cv_ct_wn=osp-search&amp;amp;pf_rd_s=desktop-sx-inline&amp;amp;pd_rd_w=qgIuG&amp;amp;pf_rd_i=chromebook&amp;amp;pd_rd_wg=OLHr0&amp;amp;pf_rd_p=53b688eb-671a-4acd-886f-dc89fa36d3d2&amp;amp;pf_rd_t=301&amp;amp;pd_rd_r=4d4ed571-35bf-4be9-860c-7deaa1ce8cc4&amp;amp;pf_rd_r=QNRHZW6VWAWZ13HMDGF7&amp;amp;pf_rd_m=ATVPDKIKX0DER&amp;amp;creativeASIN=B075JSK7TR&amp;amp;pf_rd_p=53b688eb-671a-4acd-886f-dc89fa36d3d2&amp;amp;pd_rd_wg=OLHr0&amp;amp;pd_rd_i=B075JSK7TR&amp;amp;pf_rd_s=desktop-sx-inline&amp;amp;pf_rd_t=301&amp;amp;pf_rd_i=chromebook&amp;amp;pf_rd_m=ATVPDKIKX0DER&amp;amp;pd_rd_w=qgIuG&amp;amp;pf_rd_r=QNRHZW6VWAWZ13HMDGF7&amp;amp;pd_rd_r=4d4ed571-35bf-4be9-860c-7deaa1ce8cc4&#34;&gt;Chromebook&lt;/a&gt; or VDI thin client. Dramatic changes do not happen quickly in the networking world, and there are a number of simple reasons why&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Mean time to replacement is somewhere between 5 and 10 years depending on the environment&lt;/li&gt;
&lt;li&gt;Standards for networking take &lt;strong&gt;For-ev-er&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So, even if the time to replace lifecycle is short, the windows for new tech standards, vendor implementation, and knowledge dissemination to occur rarely, if ever, line up. What this means is that new tech is very slow to adopt in the network world. Even I make the mistake of being far too impatient with this process sometimes, as &lt;a href=&#34;https://twitter.com/bcjordo?lang=en&#34;&gt;Jordan Marti&lt;/a&gt;n called me out on in a &lt;a href=&#34;https://thenetworkcollective.com/2018/02/otc-nfd17/&#34;&gt;Network Collective podcast&lt;/a&gt; a few months ago (p.s., it&amp;rsquo;s a fun listen - check it out). Back to automation. As IT changed in non-service providers from a questionable money sink to a potentially critical revenue generating business and communications environment the generalist IT workers slowly morphed into the specialists. Developers, Network Engineers, Systems Engineers, phone system admins, etc. As this occurred, the disciplines fractured and the skillsets refined, and in many cases lost the generalist foundation in trade for a deeply focused skill set.&lt;/p&gt;

&lt;h2 id=&#34;the-sdn&#34;&gt;The SDN&lt;/h2&gt;

&lt;p&gt;After a decade or two of this shift, SDN blows onto the scene. SDN, as it emerges and becomes the new marketing darling of many a start up and huge company alike, promises to destroy boundaries and obsolete basically everything - equipment, skill sets, people, cars, dogs, cats, water, air&amp;hellip;&amp;hellip;.everything. The issue is that from a few research products that had ground breaking ideas came a monster. As over-hyped, over-marketed, and under developed juggernaut that had a different meaning to anyone you asked. Whole some folks plugged away quietly on &lt;a href=&#34;https://faucet.nz/&#34;&gt;projects that actually wor&lt;/a&gt;k, and &lt;a href=&#34;http://www.forwardingplane.net/2012/11/sdn-across-domains-in-the-wan-a-novice-look/&#34;&gt;experimented&lt;/a&gt; with &lt;a href=&#34;https://esnetupdates.wordpress.com/2015/11/03/esnets-nick-buraglio-leading-scinets-first-sdn-effort-at-sc15/&#34;&gt;deployments meant to function in production&lt;/a&gt;, the marketing machines created more and more hype and delivered only a few promises. This is the far out pendulum swing. Many operators recoiled. Enterprises said &amp;ldquo;why?&amp;rdquo;, and folks trying to push boundaries with new deployments were saying &amp;ldquo;&lt;em&gt;wait, let&amp;rsquo;s figure out &amp;ldquo;what&amp;rdquo; before we ask &amp;ldquo;why?&amp;rdquo;&lt;/em&gt;&amp;rdquo;. Then the pendulum started swinging back. Automation is back, and now there are &lt;a href=&#34;https://www.ansible.com/&#34;&gt;products&lt;/a&gt; and tools, and &lt;a href=&#34;https://www.ipspace.net/Hands-On_Network_Automation&#34;&gt;resources&lt;/a&gt;. We&amp;rsquo;re centering on a safer alternative that conservative enterprises can deploy safely and without event. We&amp;rsquo;re back to the fundamentals and the basics of what worked long ago - but now we have help.&lt;/p&gt;

&lt;h2 id=&#34;my-take&#34;&gt;My take&lt;/h2&gt;

&lt;p&gt;Make no mistake, I am still believer in the fundamentals that something resembling SDN brings to the table and have been working on &lt;a href=&#34;https://sc18.supercomputing.org/blog/&#34;&gt;significant SDN projects even recently&lt;/a&gt;, including moving our entire office over to FAUCET controlled switches (more on this soon), and a fair amount of work in the segment routing / PCE space. However, I am not a fan of the marketing machine, especially when there is a poverty of useful data to build said marketing from, and said marketing contains an &lt;a href=&#34;https://www.forwardingplane.net/2013/03/my-sdn-soapbox-now-with-ipv6/&#34;&gt;overabundance of sensational FUD&lt;/a&gt;. New technology needs to be supportable to be deployed, and it happens, very, very slowly. Much like IPv4 to IPv6, Frame Relay to ATM, and circuit switched to packet switched, as SDN technologies become more and more exposed and easier to use, they become &amp;ldquo;just another thing&amp;rdquo;, and that takes time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trouble with Tribbles .....errr NAT</title>
      <link>https://forwardingplane.net/post/trouble-with-tribbles-errr-nat/</link>
      <pubDate>Mon, 16 Jul 2018 10:24:00 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/trouble-with-tribbles-errr-nat/</guid>
      <description>

&lt;p&gt;As a follow up to my &lt;a href=&#34;https://www.forwardingplane.net/2018/06/nat-discussions/&#34;&gt;last post&lt;/a&gt;, I wanted to dive a little deeper into the world of address translation and to suss out some of the more compelling details.&lt;/p&gt;

&lt;p&gt;As I&amp;rsquo;ve said on many occasions, it pains me to see NAT referenced as a security mechanism. That said, where PNAT can be beneficial is in an overall privacy strategy, however, even that is comparatively low value and given the current state of global IPv4 allocations, arguably a detriment to usability - we’ll get to that - before we do, it is important to understand what ’NAT” as we call it today actually is, and to do that we need to explain all of the types of address translation (yes, there are several). When what was designed&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Static, or one-to-one NAT&lt;/strong&gt; This is the original and most simple. It is comprised of an internal and corresponding external IP address. Every machine on the network still needs a public IP address for external mapping with this model. It was originally designed to solve the problem NAT was built to address: address translation between two networks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dynamic NAT&lt;/strong&gt; This is a bit of a hybrid of static and the next type, NAPT. In this model, a NAT router maintains a set of external IPv4 address and cynically allocates one to internal addressed for outbound communication.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Network Address port translation (NAPT)&lt;/strong&gt; This is what most folks will mean when they say “NAT”. Really, this is address masquerading with port translation. This is what is often confused with a security tool, given that it provides a low level of obfuscation from external scanning and “hides” the hosts behind an externally facing address. This mechanism is typically conflated with stateful firewall implementation, which is not inclusive of this implementation.&lt;/p&gt;

&lt;p&gt;Because of the enterprise expectation of a modern UTM, NAPT is unfortunately used interchangeably by many security professionals. What NAPT actually buys is a mechanism for obfuscating many hosts to a smaller number of addresses, typically on the same device. By removing a single data reconnaissance vector (scanning of ipv4) you’re actually providing a new one that’s much easier to exploit (state table exhaustion). While it does work to prevent inbound scanning, that’s really all it does other than allow for network and port translation, it should not be expected to provide anything more than simple obscuring of the internal data. NAPT as security is primarily predicated on the notion that your source address is critically important and should be obscured. While this is true to a certain extent, this believe is somewhat antiquated and should be treated as such. Tracking via source address is still completely doable with simple tools, and geolocation is completely available (assuming it is correctly registered) based on the NAPT address. This is true of IPv4 and IPv6. What NAT does accomplish is prevention of scanning and external recon of potentially sensitive systems. That’s it. I would also assert that this over-stated sense of usefulness users a false sense of protection and encourages a relaxed diligence on hardening end hosts. The same level of protection can very easily be accomplished on a public IPv4 or IPv6 prefix with a simple stateful firewall or host based firewall. What NAPT buys is two fold:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Extension of IPv4 resources&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A poor shortcut to resource protection&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If sized appropriately, the expense of this is a very under-stated price tag&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A sizable cost for right-sized UTM&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Acceptance of the risk of a state table exhaustion DoS event&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Insecure internal resources, IoT devices, or BYOD nodes that are compromised or vulnerable.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Without proper east-west filtering and a tight egress policy, this sheen of protection becomes significantly less useful. Add in the likelihood of &lt;a href=&#34;https://en.wikipedia.org/wiki/Carrier-grade_NAT&#34;&gt;carrier grade NAT (CGNAT)&lt;/a&gt; due to extreme &lt;a href=&#34;https://en.wikipedia.org/wiki/IPv4_address_exhaustion&#34;&gt;exhaustion of IPv4 resource&lt;/a&gt;, and you compound the limits with additional operational and troubleshooting overhead. IPv6, while the correct next step, does solve a large part of the issues, but not without it’s own [mostly one-time] costs, and given the large uptake in IPv6 from both the client and content perspectives, it would behoove every organization to get their IPv6 strategy sorted and underway.&lt;/p&gt;

&lt;h3 id=&#34;my-take&#34;&gt;&lt;strong&gt;My take&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;In the olden times of winnuke, providing a layer of confusion between the delicious caramel center of your network resource and the dragons of the internet was pretty important. The tracking mechanisms and scanning was mostly thwarted by the thin candy shell of the NAPT device. While this is still a very important aspect in your network architecture and defense in depth strategy, understanding the real risks and true value is important. The belief that NAPT provides your security (or that it is even a security tool at all) is somewhat misguided. With regard to privacy, the real threats lie in the metadata collection, and unless you are high profile or have a highly targeted business or personal footprint, the security incidents are far more nuanced and often happen at higher layers. In addition, lets not forget that a very, very real threat is not from random poking at our externally facing network resources, but in the social engineering attacks that are readily let right in the door. In addition, there are a number of significant risks that NAPT beings to bear based on it’s use of a state table to track IP to port mappings. All of these details need to be considered and continually revisited for relevance.&lt;/p&gt;

&lt;h3 id=&#34;further-study&#34;&gt;&lt;strong&gt;Further study&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Understanding that this is a very high profile, sensitive, and polarizing subject, additional reading and research is important. A few good white papers detailing shortcomings and misconceptions surrounding NAPT can be found &lt;a href=&#34;https://www.google.com/amp/s/www.calyptix.com/top-threats/ddos-attacks-101-types-targets-motivations/amp/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://f5.com/resources/white-papers/the-myth-of-network-address-translation-as-security&#34;&gt;here&lt;/a&gt;. In addition, &lt;a href=&#34;https://thenetworkcollective.com/&#34;&gt;The Network Collective&lt;/a&gt; invited me back to discuss privacy in networking. What resulted was a very spicy podcasts that really highlights the complexity of privacy as a concept in today&amp;rsquo;s internet.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://vimeo.com/272381393&#34;&gt;Ep28 - For The Love Of NAT&lt;/a&gt; from &lt;a href=&#34;https://vimeo.com/networkcollective&#34;&gt;Network Collective&lt;/a&gt; on &lt;a href=&#34;https://vimeo.com&#34;&gt;Vimeo&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Field Area Networking</title>
      <link>https://forwardingplane.net/post/field-area-networking/</link>
      <pubDate>Fri, 04 May 2018 13:38:15 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/field-area-networking/</guid>
      <description>

&lt;p&gt;It&amp;rsquo;s no secret that RF technologies and what like to call &amp;ldquo;specialty networking&amp;rdquo; are two of my favorite things in the networking space. &lt;strong&gt;Put them together and it is like chocolate and peanut butter!&lt;/strong&gt; Now, some may not consider Field Area Networking (FAN) to be &amp;ldquo;unconventional&amp;rdquo;, but it certainly falls well outside of the space of what is typically traditional enterprise networking. That said, Cisco&amp;rsquo;s FAN briefing at &lt;a href=&#34;http://techfieldday.com/event/nfd17/&#34;&gt;Network Field Day 17&lt;/a&gt; really got me excited and thinking about the alternatives for the IoT space. Other than cellular LTE or &lt;a href=&#34;https://www.link-labs.com/blog/what-is-lte-m&#34;&gt;LTE-M&lt;/a&gt;, there are few options for remote IoT devices with limited power draw and bandwidth requirements. So I went down the twisted path of investigating that space, and recently, I recorded a &lt;a href=&#34;https://thenetworkcollective.com/&#34;&gt;Network Collective&lt;/a&gt; short take on the subject, available below. The NFD 17 Cisco FAN briefing that this is based around is also worth a watch - this is really innovative stuff that many of us probably don&amp;rsquo;t think about. &lt;a href=&#34;https://vimeo.com/253197120&#34;&gt;Cisco Innovations for the Field Area Network with Rupak Chandra&lt;/a&gt; from &lt;a href=&#34;https://vimeo.com/sfoskett&#34;&gt;Stephen Foskett&lt;/a&gt; on &lt;a href=&#34;https://vimeo.com&#34;&gt;Vimeo&lt;/a&gt;.  &lt;/p&gt;

&lt;h3 id=&#34;nick-s-take&#34;&gt;Nick&amp;rsquo;s take:&lt;/h3&gt;

&lt;p&gt;As we talk about things like cloud migration, automation, orchestration, and security architectures, lets consider the sheer scale of not just IoT networking but the sensor and other industrial networking _&lt;strong&gt;outside&lt;/strong&gt; _of the enterprise space. The sheer number of devices to be managed in these spaces is stupefying, and the transport of the data created by these networks as well as the management of the devices and network elements is a non-trivial detail. Building out networks such as a sensor network has a completely different scope and scale than a stereotypical enterprise or even a carrier service provider network. Keeping in mind just the number of hosts things like addressing schema become a critical part of the architecture (spoiler: you&amp;rsquo;re probably not going to be able to scale IPv4). Power and environmental considerations are also not nearly as squishy as they can be in a nice, controlled data center. Considering those data points, it&amp;rsquo;s pretty clear that there is plenty of interesting stuff happening in both the engineering and security areas.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Strategy Series: Build vs. Buy (sorta)</title>
      <link>https://forwardingplane.net/post/strategy-series-build-vs-buy-sorta/</link>
      <pubDate>Mon, 19 Feb 2018 22:53:03 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/strategy-series-build-vs-buy-sorta/</guid>
      <description>

&lt;p&gt;Build vs. buy is an often lamented and always hotly debated question in all aspects of IT, however, if one is able to truly look at all angles the answer is typically straightforward and can be rooted in one simple strategy: don&amp;rsquo;t reinvent the wheel.&lt;/p&gt;

&lt;h1 id=&#34;don-t-reinvent-the-wheel&#34;&gt;Don&amp;rsquo;t reinvent the wheel&lt;/h1&gt;

&lt;p&gt;Too many times we as an industry don&amp;rsquo;t do our homework - we are all guilty of it - and we reinvent a wheel. Make no mistake, there are true reasons to revisit, revise and reinvent. Lets use an example that &lt;a href=&#34;https://github.com/buraglio/pfrancid&#34;&gt;I&lt;/a&gt; &lt;a href=&#34;https://github.com/buraglio/vdxrancid&#34;&gt;am&lt;/a&gt; &lt;a href=&#34;https://github.com/buraglio/alurancid&#34;&gt;fairly&lt;/a&gt; &lt;a href=&#34;https://github.com/buraglio/sonrancid&#34;&gt;familiar&lt;/a&gt; &lt;a href=&#34;https://github.com/buraglio/cienarancid&#34;&gt;with&lt;/a&gt;: RANCID &lt;a href=&#34;http://shrubbery.net/rancid/&#34;&gt;RANCID&lt;/a&gt; code is 20+ years old and pretty messy. RANCID3 is a rewrite that in my opinion makes the already confusing ball of Perl, Expect, and shell even more confusing. &lt;a href=&#34;https://github.com/ytti/oxidized&#34;&gt;Oxidized&lt;/a&gt; made that process more elegant and arguably more flexible and extensible. That was a good call. Build vs buy is a tough question and as an industry we tend to think about resources in a lopsided way, which further increases that complexity. Resources have always been and will always be finite, and no matter if you build or buy, you are expending your resources. Lets break down the resources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Time&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That&amp;rsquo;s pretty much the extent of it. Everything else is driven by this. Time coasts money. It costs money in the form of salaries, overtime, downtime, etc. In IT we describe things in terms of uptime. Five 9&amp;rsquo;s is the uptime we strive for. When we have downtime, it costs money in the form of lost income or expense to repair and often both. Salaries are paid based on time, hourly, weekly, monthly, yearly. Employes trade their time for that salary regardless of how it is structured. You pay for resources that make more efficient use of time. Employers often fall into one of two buckets:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Able to hire FTE (OPEX)&lt;/li&gt;
&lt;li&gt;Able to pay vendors (CAPEX)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Obviously this isn&amp;rsquo;t always the case, but it&amp;rsquo;s very common - and if we conveniently overlook those environments that are jut to conservative to consider OPEX (i.e. they always choose buy and generally fall into the &amp;ldquo;able to pay vendors&amp;rdquo; category), it&amp;rsquo;s fairly easy to map build vs buy into those models. Can you support running open source or white box solutions, operationally? Will the OPEX actually save you money when compared to the CAPEX changes they require to make happen? Should you pay for an off the shelf solution and hope that the support you buy can address the issues you&amp;rsquo;ll have? [&lt;em&gt;My strong opinion is that they almost never can, but the comfort that they provide to legal departments and C level execs is what they actually purchase&lt;/em&gt;] It is important to note that different environments introduce very different edge cases, and with many highly technical people, these edge cases have a tendency to creep in and drive a large part of our architectures, but it also gives us a veneer over our needs and requirements process that makes it easier to say &amp;ldquo;we&amp;rsquo;re special and we have hard requirements for not only A and B but also C, D, E and F&amp;rdquo;. C, D, E, and F are likely so edge case that we really don&amp;rsquo;t *need* them. This is where It gets messy and where the hyperscalers have done it right: Say no.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://giphy.com/gifs/reactionseditor-3o7btT1T9qpQZWhNlK&#34;&gt;via GIPHY&lt;/a&gt; Interdomain multicast? Nope. Requirements for full global tables on every device? Nope. If we really ask ourselves if the requirements are actually requirements or if they are simply desirable because they may make things easier or may satisfy a 5-10% use use case, then maybe we should revisit how we&amp;rsquo;re actually developing our needs and requirements. Mapping business (or other strategic) requirements into technology can be difficult, especially if there is no direct correlation to profit or loss. We are a culture of wheel inventors and we embrace it, but 80-85% of the time our wheels can be dead simple and still roll us where we need to go. &lt;strong&gt;&lt;em&gt;What we get &amp;ldquo;for free&amp;rdquo; with that is standardization and ease of management&lt;/em&gt;&lt;/strong&gt; (lower CAPEX). If we look back at history as an example, no sane person wants to run a network that routes AppleTalk, IPX, IPv4, IPv6 and transits DECNet. that sucked. It was too complicated. It was buggy. We simplified it down to IPv[&lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;6&lt;/sub&gt;] and low and behold most of the gear got more stable, configurations got simpler, and networks got easier to run. We should learn from that. Make no mistake, I realize that reinventing wheels to make them roll faster, longer, etc. is called innovation. However, along with our needs and requirements we need to put serious consideration into our business strategy. Is our business to innovate? Are we going to see direct or indirect improvements to CAPEX or OPEX if we &lt;em&gt;do&lt;/em&gt; innovate. Are we factoring in the &lt;em&gt;cost&lt;/em&gt; of the innovation? Where this starts to get even more fuzzy is in the opensource world. In this space &amp;ldquo;build&amp;rdquo; can be defined as self supporting, meaning &amp;ldquo;use of opensource products with no formal or contractual support structure&amp;rdquo;, which a very large amount of organizations are very wary of (and many actively avoid). These are all important questions that must be addresses when deciding on the strategy of build vs buy - it&amp;rsquo;s not as straight forward and simple of a question as &amp;ldquo;build or buy&amp;rdquo;, it seems. If you&amp;rsquo;re looking for a different perspective on a very similar topic, check &lt;a href=&#34;https://rule11.tech&#34;&gt;Russ White&lt;/a&gt;&amp;rsquo;s (yes, &lt;a href=&#34;https://www.linkedin.com/in/riw777/&#34;&gt;THAT Russ White&lt;/a&gt;) post on &lt;a href=&#34;https://rule11.tech/enterprise-versus-provider/&#34;&gt;Enterprise vs. Provider&lt;/a&gt;. While not entirely similar, it points out that we have problems and solutions, and that knowing what both of those are is critical to success regardless of their ecosystem. This is key. We need to look at the whole picture. &lt;em&gt;My take: We need to look at the entire picture. It&amp;rsquo;s not as simple as one question. Personally I tend to lean more toward build, but for the majority of my career I was in environments that had extremely clued engineers and support staff. Is this for everyone? Nope. Is it a viable option, absolutely. You invest in people or you invest in contracts. I&amp;rsquo;d rather invest in really, really good people. &lt;/em&gt; &lt;em&gt;When it comes down to innovation, it&amp;rsquo;s a little more complicated:&lt;/em&gt; &lt;em&gt;1. if wheel exists don&amp;rsquo;t build wheel.&lt;/em&gt; &lt;em&gt;2. If the wheels aren&amp;rsquo;t exactly the shape or size you need, augment the wheels and contribute your augmentations back for review and inclusion in the wheel plans and inventory where possible and appropriate.&lt;/em&gt; &lt;em&gt;3. If the wheels don&amp;rsquo;t exist, build a wheel and share the plans for the wheel whenever you can.&lt;/em&gt;```
#!/usr/bin/python&lt;/p&gt;

&lt;p&gt;if wheel == &amp;lsquo;yes&amp;rsquo;:
 print(&amp;lsquo;use existing wheel&amp;rsquo;)
 elseif &amp;lsquo;yes, but incomplete&amp;rsquo;:
 print(&amp;ldquo;augment wheel, contribute wheel changes&amp;rdquo;)
 elseif no:
 print(&amp;ldquo;build wheel, share plans&amp;rdquo;)
 print &amp;ldquo;Miller Time&amp;rdquo;
```* Code is provided as-is and is likely incorrect, we take no responsibility for poor code or fallout from running said code&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Strategy Series: How do you view outside of your network?</title>
      <link>https://forwardingplane.net/post/strategy-series-view-outside-network/</link>
      <pubDate>Sat, 10 Feb 2018 16:58:28 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/strategy-series-view-outside-network/</guid>
      <description>

&lt;p&gt;In the tradition of my &lt;a href=&#34;https://www.forwardingplane.net/topics/nix4neteng/&#34;&gt;NIX4NetEng&lt;/a&gt; series I&amp;rsquo;m going to dive deep into the world of strategy, and specifically into the strategy of how we look at and operate our networks, the data they generate and the analytics that are available (and often overlooked) in how networks are managed both long term and day-to-day. So, in the spirit of visibility, lets think about how typical networks are monitored. My guess is that you either already know, or will soon realize that v&lt;em&gt;isibility and testing across disparate networks is hard.&lt;/em&gt; This is a &lt;strong&gt;big&lt;/strong&gt; topic, so sit back, relax, get your feet up and prepare for a magical journey into the fun and fantastical world of network visibility!&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://giphy.com/gifs/magic-krhB8ydCQiYZq&#34;&gt;via GIPHY&lt;/a&gt; I&amp;rsquo;m going to glaze over the low hanging fruit of SNMP monitoring - you have all of that right? Yes? Good. No?!?! Shame on you&amp;hellip;I&amp;rsquo;l do another post of some of my &lt;a href=&#34;https://www.librenms.org/&#34;&gt;favorite tools&lt;/a&gt; soon and you can shamefully download them and set them up, head hung low (until they&amp;rsquo;re up monitoring and alerting, at which point you can raise your head up high!). Lets make a very, very bold assumption that you totally understand how your internal network works, you have graphing, up/down statistics, traffic baselines and visibility into &lt;a href=&#34;http://www.forwardingplane.net/2017/12/what-is-your-netflow-strategy/&#34;&gt;traffic flow&lt;/a&gt; and &lt;a href=&#34;http://www.forwardingplane.net/2017/10/configuration-backups-opportunity-automation-management/&#34;&gt;configurations&lt;/a&gt;. Don&amp;rsquo;t worry, if you don&amp;rsquo;t have those things you can link to a few options here or wait and I&amp;rsquo;ll circle back around to them in later topics.&lt;/p&gt;

&lt;h1 id=&#34;visibility-and-testing-across-diverse-networks-is-hard&#34;&gt;&lt;em&gt;&amp;ldquo;Visibility and testing across diverse networks is hard.&amp;rdquo;&lt;/em&gt;&lt;/h1&gt;

&lt;p&gt;OK, so visibility. &lt;img src=&#34;http://www.nickburaglio.com/wp-content/uploads/2015/09/day7.jpg&#34; alt=&#34;&#34; /&gt; Any network engineer with some experience under their belt has gotten the problem report of &amp;ldquo;the internet is down&amp;rdquo; or &amp;ldquo;the internet is slow&amp;rdquo;. Yup, we all know them, we all love them. We even had an internal joke at a previous employer of mine that we could &amp;ldquo;ping the internet&amp;rdquo;, in that we created a CNAME of &amp;ldquo;theinternet&amp;rdquo; for a host that had high uptime.&lt;code&gt;
(~) heelflip $ ping theinternet
PING theinternet (10.142.143.167): 56 data bytes
64 bytes from 10.14.143.167: icmp\_seq=0 ttl=54 time=0.794 ms
64 bytes from 10.14.143.167: icmp\_seq=1 ttl=54 time=0.768 ms
64 bytes from 10.14.143.167: icmp\_seq=2 ttl=54 time=0.734 ms
64 bytes from 10.14.143.167: icmp\_seq=3 ttl=54 time=0.732 ms
64 bytes from 10.14.143.167: icmp\_seq=4 ttl=54 time=0.758 ms
64 bytes from 10.14.143.167: icmp\_seq=5 ttl=54 time=0.761 ms
&lt;/code&gt;Right, so you get the internal network. What about when you get to the part that you don&amp;rsquo;t control and can&amp;rsquo;t see into? That&amp;rsquo;s harder, but rest easy - there are a number of ways to go about gathering the necessary details. What should those data sources be? Let me throw down what I think are important to track to really understand what the heck is going on outside of your AS or sphere of influence.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Paths to common destinations (&lt;a href=&#34;https://google.com&#34;&gt;google&lt;/a&gt;, &lt;a href=&#34;https://www.servicenow.com&#34;&gt;servicenow&lt;/a&gt;, &lt;a href=&#34;https://www.salesforce.com&#34;&gt;SalesForce)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Route table for all peerings (if taking more than default and are using eBGP)&lt;/li&gt;
&lt;li&gt;Latency statistics from your site to common destinations (see 1.)&lt;/li&gt;
&lt;li&gt;Latency statistics from outside of your network to your site&lt;/li&gt;
&lt;li&gt;Latency (and possibly throughput) statistics to intermediary points across your typical paths&lt;/li&gt;
&lt;li&gt;External route table and path statistics&lt;/li&gt;
&lt;li&gt;Packet loss statistics&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That&amp;rsquo;s a decent amount of data. How can this be done? Well, let me tell you, there are a few ways but drawing them all together can be a daunting task. This can be accomplished by looking at data produced by &lt;a href=&#34;https://oss.oetiker.ch/smokeping/&#34;&gt;smokeping&lt;/a&gt; or &lt;a href=&#34;https://github.com/perfsonar/owamp&#34;&gt;owamp&lt;/a&gt; with an SNMP graphing tool for interface stats and &lt;a href=&#34;https://bgpmon.net/&#34;&gt;BGPMon&lt;/a&gt; and Peermon for BGP information. An opensource product called &lt;a href=&#34;https://www.perfsonar.net/&#34;&gt;perfSonar&lt;/a&gt; rolls a lot of this together, but there are commercial packages such as &lt;a href=&#34;https://www.thousandeyes.com/&#34;&gt;ThousandEyes&lt;/a&gt; that offer these types of statistics across a large swath of the internet as well. &lt;a href=&#34;https://atlas.ripe.net/&#34;&gt;RIPE ATLAS&lt;/a&gt; has a great deal of statistics that can be easily queried  and has a large install base too. If you are a savvy coder you can grab some good information from the &lt;a href=&#34;https://atlas.ripe.net/docs/api/v2/manual/&#34;&gt;RIPE ATLAS API&lt;/a&gt;. If you don&amp;rsquo;t have the resources, capability, or time to do that then there is an option for a turnkey solution. &lt;a href=&#34;https://www.thousandeyes.com&#34;&gt;ThousandEyes&lt;/a&gt; has a strong offering and there is a great deal of information that they gather. They also have very good presence and availability of information about their product, most recently presenting at &lt;a href=&#34;http://techfieldday.com/appearance/thousandeyes-presents-at-networking-field-day-17/&#34;&gt;Network Field Day 17&lt;/a&gt; (and historically at &lt;a href=&#34;http://techfieldday.com/appearance/thousandeyes-presents-at-networking-field-day-6/&#34;&gt;NFD 6&lt;/a&gt;, &lt;a href=&#34;http://techfieldday.com/appearance/thousandeyes-presents-at-networking-field-day-8/&#34;&gt;NFD 8&lt;/a&gt;, and &lt;a href=&#34;http://techfieldday.com/appearance/thousandeyes-presents-at-networking-field-day-12/&#34;&gt;NFD 12).&lt;/a&gt;I was a delegate at NFD 17 and was pleased to see another tool that provides visibility into BGP, a very often overlooked and yet unbelievablycritical and useful viewpoint which has historically been difficult to see outside of tools like &lt;a href=&#34;http://www.forwardingplane.net/2015/03/opendns-acquires-bgpmon-and-the-future-of-route-monitoring/&#34;&gt;BGPMon&lt;/a&gt;. (see my previous &lt;a href=&#34;https://www.forwardingplane.net/topics/nix4neteng/&#34;&gt;NIX4NetEng&lt;/a&gt; &lt;a href=&#34;http://www.forwardingplane.net/2014/03/bgp-tools-troubleshooting-and-monitoring-external-routing-in-a-nutshell/&#34;&gt;post about BGP visibility&lt;/a&gt;). &lt;a href=&#34;http://techfieldday.com/appearance/netbeez-presents-at-networking-field-day-9/&#34;&gt;NetBeez&lt;/a&gt; also has a reasonable offering but last I have looked it doesn&amp;rsquo;t really do much outside of a network (admittedly I may be behind the curve with their product). If you&amp;rsquo;re interested in seeing or hearing some more about these products, I did a packet pushers podcast on perfSonar a few years ago which is dated as far as feeds and speeds, but still very relevant today, you can read the show notes and listen &lt;a href=&#34;http://packetpushers.net/podcast/podcasts/show-163-open-source-perfsonar-finds-the-flaws-impacting-the-flows/&#34;&gt;here.&lt;/a&gt; For more info on ThousandEyes you can check out the latest &lt;a href=&#34;http://techfieldday.com/event/nfd17/&#34;&gt;NFD17&lt;/a&gt; videos.   The real point is that to really see the performance of your network and to fully understand the true user experience you need to have total visibility into the entire ecosystem, not just the pieces that you can control.&lt;/p&gt;

&lt;h6 id=&#34;for-anyone-wigged-out-about-the-eyeball-pic-those-are-my-eyes-7-days-after-lasik-http-www-nickburaglio-com-2015-09-02-eg-html&#34;&gt;*For anyone wigged out about the eyeball pic, those are my eyes &lt;a href=&#34;http://www.nickburaglio.com/2015/09/02/eg-html/&#34;&gt;7 days after Lasik&lt;/a&gt;.&lt;/h6&gt;
</description>
    </item>
    
    <item>
      <title>Strategy Series: What is your netflow strategy?</title>
      <link>https://forwardingplane.net/post/what-is-your-netflow-strategy/</link>
      <pubDate>Mon, 18 Dec 2017 11:15:30 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/what-is-your-netflow-strategy/</guid>
      <description>

&lt;p&gt;You have one, right? Even if your entire strategy is “collect some flow data”, there is absolutely NO reason not to have a netflow implementation, and frankly, it will save you time and money over time if you make the effort to do it. I love network data and analytics and I have waxed poetic about how important they are at every opportunity. There are a myriad of options for analytics and flow data. If you’re not doing something, you’re doing it wrong. I can go on and on about the importance of network data for budgeting, security, capacity planing, and general knowledge of what your network is actually doing, but that’s for another day (contact me directly if you really want to chat details on that subject). Today is about network flow data - the foundational bits and pieces of what the heck your network, big or small, is actually doing. I’ve been having a breakdance fight with flow data packages for almost two decades, and I’ve jotted down a few of my more notable experiences. Regardless of your needs, budget, abilities, or time, there is a solution for you.&lt;/p&gt;

&lt;p&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://giphy.com/gifs/breakin-boogaloo-shrimp-11FirB7GcukiwU&#34;&gt;via GIPHY&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;arbor-https-www-arbornetworks-com&#34;&gt;&lt;strong&gt;&lt;a href=&#34;https://www.arbornetworks.com/&#34;&gt;Arbor&lt;/a&gt;&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Arbor is the Rolls Royce of flow analytics (and DDoS mitigation) solutions. It does almost everything, has options for managed objects, DDoS scrubbing and alerting capabilities, a magnificent interface, role based access, rainbows and gumdrop houses with lollipop trees. This system is pretty darned amazing - it truly is, and that likely comes from the fact that they were one of the first, and had/have one of the largest install bases for this kind of system. They have turnkey solutions and have the unique position of being in roughly 90% of the worlds legacy tier 1 ISPs, so their DDoS and other security options are strong, fast to update, and &lt;strong&gt;&lt;em&gt;very&lt;/em&gt;&lt;/strong&gt; good. I’ve had great experience with this platform and its API. I like to think of arbor as the commercial ISP brass ring for flow data analytics. They have other solutions for enterprise and campus, but their roots are in strong ISP solutions. They’re pricey, but very, very good. Expect to need at least an FTE to really take full advantage of their very capable ecosystem, but if you dedicated the money and manpower to it, you won’t be sad.&lt;/p&gt;

&lt;h2 id=&#34;splunk-https-www-splunk-com&#34;&gt;&lt;a href=&#34;https://www.splunk.com/&#34;&gt;Splunk&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;We all know spunk as a really nice log and analytic system but what many may not realize is that Splunk is really, really good at network data and analytics as well. It’s pricey, but it’s as close as you’ll get to a turkey solution for a SIEM that can actually scale. It has the notion of customizable dashboards and visualization, as a huge amount of plugins and add on’s, but they come with a legendarily steep price tag. The saying I have always heard is “if you can afford spunk, buy spunk. If you can’t use an ELK stack (noe elastic stack)”. My experience backs this up.&lt;/p&gt;

&lt;h2 id=&#34;elk-elastic-stack-https-www-elastic-co&#34;&gt;&lt;a href=&#34;https://www.elastic.co/&#34;&gt;ELK /Elastic Stack&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;I’m a big fan of this not only because it’s essentially free, but because it’s so extremely flexible and has so many existing projects built around it. I’ve moved my go-to for net flow collection from nfdump to Elastic Stack built around the &lt;a href=&#34;https://www.manitonetworks.com/about-flow-analyzer/&#34;&gt;Manito Networks flowanalyzer&lt;/a&gt; install.   This platform takes a bit more command line jockeying and isn’t entirely turnkey, but it’s crazy flexible, had great eye candy and building the visualizations and dashboards is easy. Notable mention is &lt;a href=&#34;https://github.com/robcowart/elastiflow&#34;&gt;Elastiflow&lt;/a&gt;, which is similar but has a bit more eye candy and leverages log stash. Elastiflow doesn’t have nearly as turnkey of an install (and really has almost no “newbie” install instructions at all - but it’s a strong offering if you already know how to spin up an ELK stack and tune it.&lt;/p&gt;

&lt;h2 id=&#34;nfdump-http-nfdump-sourceforge-net&#34;&gt;&lt;a href=&#34;http://nfdump.sourceforge.net/&#34;&gt;Nfdump&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The venerable nfdump. This is what so many large networks were using (and probably still are) for their raw flow collections. This package scales exceptionally well to huge networks and has so many tools available for the CLI that it’s the de facto standard for raw flow analytics and forensics. I love this system and ran it for many, many, MANY years. It takes a but of time to learn, and may not be the right tool for you if you want a modern GUI, lots of eye candy, or are inexperienced with the UNIX/LINIX command line, but it’s got it where it counts, supports IPFix, Netflow v5, v9 and IPFIX and you can’t dog wrong with it. I have a handy how-to getting it up and running Under CentOS &lt;a href=&#34;https://www.forwardingplane.net/2014/01/install-nfsen-and-nfdump-on-centos-6-5-for-netflow-and-or-sflow-collection/&#34;&gt;here&lt;/a&gt;. When you couple this with something like &lt;a href=&#34;https://github.com/JustinAzoff/flow-indexer&#34;&gt;Justin Azoff’s flow indexer&lt;/a&gt; and &lt;a href=&#34;https://sourceforge.net/projects/nfsen/&#34;&gt;nfsen&lt;/a&gt; on the front end, you’ve got an enviable power user setup ripe for both forensics, tactical work as well as baseline generation.&lt;/p&gt;

&lt;h2 id=&#34;solarwinds-https-www-solarwinds-com&#34;&gt;&lt;a href=&#34;https://www.solarwinds.com/&#34;&gt;SolarWinds&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Solarwinds Orion is the go-to for windows based monitoring. It’s not cheap, but if you’re running a windows based monitoring system, you’re likely an enterprise and have budget for it. I have been impressed with the visualizations of this system and like that it does all of the monitoring in one package - once installed I never have to see windows (and since I can’t efficiently support windows, that’s probably a good thing - someone else will handle the OS work). The price tag can be a bit steep depending on number of nodes monitored, but it does what it claims and commercial support is decent. My one complaint is that I can’t seem to find a way to do raw data queries in a straightforward way. This may be possible and I have just not had the time or mental power to workout out. Overall it’s a worthy monitoring platform if you need your system to run on windows and can afford it. There are some older but still good videos from several Network Field Day events &lt;a href=&#34;http://techfieldday.com/companies/solarwinds/&#34;&gt;here&lt;/a&gt; and I wrote about it from a UNIX users perspective &lt;a href=&#34;https://www.forwardingplane.net/2015/07/solarwinds-orion-from-a-unix-user-point-of-view/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;live-action-networks-live-ux-https-www-liveaction-com-products-live-ux&#34;&gt;&lt;a href=&#34;https://www.liveaction.com/products/live-ux/&#34;&gt;Live Action Networks Live UX&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Another commercial option that has good support and a lot of eye candy. This was born out of work with the US Government and is a really interesting system. I’ve met with these guys several times and their team is super open to taking and feature requests and they have a good product. I first heard about them at &lt;a href=&#34;http://techfieldday.com/appearance/liveaction-presents-at-networking-field-day-7/&#34;&gt;Network Field day 7&lt;/a&gt;, their product was intriguing there and they’ve come a long way since then. Worth looking at for a turnkey solution for things like network analytics, IP-SLA,&lt;/p&gt;

&lt;h2 id=&#34;my-take&#34;&gt;My take&lt;/h2&gt;

&lt;p&gt;I like the power that an indexed set of data provides and I am willing and capable of plowing through the install of a linux based system. I’m also frugal, and for a product to really warrant my money it needs to do something that nothing else does [translated: I am willing and able to support open source solutions].&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2017/12/Screenshot-2017-12-15-20.32.57.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;That said, the Manito Networks install of Elk + Kibana (no logstash in this default install) is where I typically land due to the fact that I can get indexed flow data, nice, configurable graphs and trending statistics, and can integrate things like syslog into another index on the same system giving me the tools to do forensics on a number of topics on that system. &lt;a href=&#34;https://gitlab.com/thart/flowanalyzer/blob/master/Install/README.md&#34;&gt;The setup is crazy easy&lt;/a&gt; and really well documented, too. Someone linux-inclined can have it up and collecting flow data (sflow, netflow v5/9 or IPFIX) in an order of about 30 minutes - probably less. The take aways really, though, is that there are options available no matter your skill level or budget, so there is really no reason not to have something.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>No privacy may be the new privacy.</title>
      <link>https://forwardingplane.net/post/no-privacy-may-new-privacy/</link>
      <pubDate>Sat, 25 Mar 2017 18:06:01 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/no-privacy-may-new-privacy/</guid>
      <description>&lt;p&gt;Taking politics and putting them aside, what the new administration has &lt;a href=&#34;https://www.nytimes.com/2017/03/23/technology/congress-moves-to-strike-internet-privacy-rules-from-obama-era.html?_r=0&#34;&gt;been attempting to change&lt;/a&gt; with regard to internet privacy is something we should &lt;em&gt;&lt;strong&gt;all&lt;/strong&gt;&lt;/em&gt; be informed about. Wether you have a tin foil hat or don&amp;rsquo;t care, &amp;ldquo;knowing is half the battle&amp;rdquo;. The other half is doing - which I will also lend some brief insight to (sorta). What&amp;rsquo;s changing? Nothing yet (as of the time of this writing). What will likely change? The ability of your internet (mobile or not) to sell your browsing habits and personal usage data. What does this mean? Well, it means that if you visit facebook, amazon, JC Penny, or buy-adult-toys.com a lot, that information can be sold to advertisers, private companies, etc., etc. &amp;ldquo;But I use SSL, I&amp;rsquo;m safe&amp;rdquo;. Nope. DNS query data - the requests made for a domain name like google.com, used to map a name to an IPvX address - that can be sold too. The content of the browsing is great, but the knowledge that a site was visited is just as useful&amp;hellip;and this data is generated not just by traditional &amp;ldquo;browsing&amp;rdquo;, everything that touches the internet uses it. Apps, Games, everything. Removing these rules also means that there is no oversight into how this collection can be done, what kind of data - sensitive or not - can be collected and sold and to whom. That&amp;rsquo;s what deregulation looks like, folks.&lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2017/03/personal.info_.jpg&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2017/03/personal.info_.jpg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt; What does this mean for the average internet user like, say, my Mom or Dad? It means that when they look at ANYTHING online, it&amp;rsquo;s likely going to be collected, indexed, data mined, and then sold to be further data mined and then these users will get targeted for a barrage of advertising. Worse yet, this data is ripe for misuse. What if the data is compromised? Sorry. That&amp;rsquo;ll suck for sure. Even worse that than, what if that data is used by nation states? What if it&amp;rsquo;s misinterpreted? It&amp;rsquo;s a mess. Has this data been used in this manner in the past? Sure. All of the providers use it internally. &lt;a href=&#34;http://money.cnn.com/2016/07/25/technology/yahoo-verizon-deal-sale/&#34;&gt;Verizon bought yahoo&lt;/a&gt; for this reason.  The real issue is that most people do not understand what all of this means. Since the internet is a completely traceable environment in 99.999% of cases, unlike really anything prior, this is paramount. What can you do? Well, if you&amp;rsquo;re not technical, good luck. Perhaps if this happens it will spark a new industry of private overlays like Tor to be commercialized and widely adopted. Wait with the FCC leaning toward rolling back net neutrality those services could likely be slowed or blocked completely. Sorry. On the fringes are the mom-and-pop ISPs - they still exist. WISPs, small and rural providers. These are less likely to be the safest bet in the future should this come to pass. Mobile metadata - what will generate the majority of the controversy - is likely to be the most often sold because there will be such a diverse and deep pool of data. Another of the side effects is this could potentially be an even higher adoption of SSL, which is good, but may also lead to a higher adoption of the vile SSL decryption practice. Lets hope not. What will I do? Not sure. I have extensive experience running DNS servers and VPNs. I may just start connecting to one of my VPS devices and run everything over OpenVPN from both mobile and traditional connections. There are some super simple &lt;a href=&#34;https://github.com/kylemanna/docker-openvpn&#34;&gt;docker how-tos&lt;/a&gt; out there that Ive used in the past. VPS service are cheap, I have a few but my &lt;a href=&#34;https://prgmr.com/xen/&#34;&gt;prgmr.com&lt;/a&gt; VPS is my favorite. Don&amp;rsquo;t forget to tunnel IPv6 too. Welcome to 2017.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BGP RPKI - why aren&#39;t we using it more?</title>
      <link>https://forwardingplane.net/post/bgp-rpki-why-arent-we-using-it/</link>
      <pubDate>Sat, 21 May 2016 16:33:44 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/bgp-rpki-why-arent-we-using-it/</guid>
      <description>&lt;nav&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#image-created-from-surfnet-rpki-page&#34;&gt;Image created from SURFNet RPKI page.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/nav&gt;

&lt;p&gt;     I was recently at a meeting where BGP RPKI was the topic de jour. While this has been a topic that I have visited on occasion of the last few years and something I wanted to spend significant time on, I have found that setting aside the time has been difficult and sparse, much like the deployment of BGP RPKI. In order to better understand the options available, it&amp;rsquo;s important to break down the pieces and terminology involved; BGP is daunting enough to those unfamiliar with it and adding PKI on top of that can be even more so. So, what are these bits and pieces and why have we not done more to adopt it?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;BGP&lt;/strong&gt; - the venerable and foundational protocol that quite literally runs the internet. BGP allows an organization to announce and exchange it’s IPv4 and IPv6 resources with other organizations.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.arin.net/resources/rpki/&#34;&gt;&lt;strong&gt;Resource Public Key Infrastructure&lt;/strong&gt;&lt;/a&gt; - From &lt;a href=&#34;https://www.arin.net/resources/rpki/&#34;&gt;ARIN&lt;/a&gt;: &lt;em&gt;Using cryptographically verifiable certificates, RPKI allows IP address holders to specify which Autonomous Systems (AS&amp;rsquo;s) are authorized to originate their IP address prefixes. These statements, known as Route Origin Authorizations (ROAs), allow network operators to make informed routing decisions, and help secure Internet routing in general. &lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ROA&lt;/strong&gt; - Route Origin Authorizations - Who is authorized to originate or source these prefixes?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ROV&lt;/strong&gt; - Route Origin Validation - Can we validate, cryptographically, that the origin of this resource (for example, 8.8.8.8) is authorized to originate or source these prefixes?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;     Many of the details of RPKI are actually not even technical, both with ARIN and with vendors, there exists complications that make the technical pieces look like child’s play. Legality of the licensing and housing of authoritative certificates are complicated, shrouded in legalese due to the nature of what they represent. This proves to be a show stopper for a lot of older organizations that have grandfathered address space and may not have gone through the ARIN agreement process any time in the recent past [note: supposedly this process is required for ARIN IPv6 space, so most of that _should_ be covered. Other regions may have easier, lower hurdles - I’ve heard good things about RIPE’s process - but I have no experience with it. The legal issues with contracts and signing certificates may also prove to be troublesome to enterprises, most of which are very conservative and slow to adopt anything new ::cough:: IPv6 ::cough::.  Certificate generation and maintenance is also considered difficult in many cases, the details can be confusing and the documentation overwhelming or difficult to find.&lt;/p&gt;

&lt;p&gt;On top of those non-technical issues, platforms with large install bases are sparsely supported - although this is changing.&lt;/p&gt;

&lt;p&gt;     There have been a &lt;a href=&#34;http://www.bgpmon.net/large-scale-bgp-hijack-out-of-india/&#34;&gt;number&lt;/a&gt; of &lt;a href=&#34;http://www.bgpmon.net/large-hijack-affects-reachability-of-high-traffic-destinations/&#34;&gt;recent&lt;/a&gt;, high profile route hijacks. If you’re ever curious to see what they were, BGPMon typically has a post-mortem shortly after they occur. This is a big deal. There are a number of ways they could have been prevented, too one of which is BGP RPKI. Is that worth the overhead? I think anyone that has had to scramble to figure out what was going on during one of these events would argue yes. But even with that, we have minimal adoption. With the significant movement to cloud based work, enterprises, service providers, academic institutions and even savvy end users should ask themselves a few important questions before doing your risk analysis:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Do your cloud providers do RPKI?&lt;/li&gt;
&lt;li&gt;Does your upstream service provider or peering partner honor invalid routes?&lt;/li&gt;
&lt;li&gt;Does your upstream service provider or peering partner even support prefix or AS-Path filtering?&lt;/li&gt;
&lt;li&gt;How does the effect BGP blackhole routing for security filtering?&lt;/li&gt;
&lt;li&gt;How do you deal with invalid routes? (alert, set preference, drop, etc.)&lt;/li&gt;
&lt;li&gt;How do you handle invalid routes that may be more specific?&lt;/li&gt;
&lt;li&gt;Why have I not deployed BGP RPKI yet?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;My perspective:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;    Unfortunately, the feeling I get is very similar to that of things [that we actually need] such as IPv6 and DNSSec. Tools that make our resources safer,  but are often overlooked due to increased operational complexity.&lt;/p&gt;

&lt;p&gt;It is really about risk analysis: Is the risk of not having this worth the effort of maintaining it?  Since we [as an internetworking ecosystem] been clear in our actions that necessary things as obvious and straightforward as appropriate prefix filtering and IPv6 deployment are in many cases above and beyond, it should come as no surprise that adding complexity on top of “stuff that just works” is’t happening on a large scale. Even with repeated proof that changes would alleviate risk, we don’t do it because what we have has been deemed “good enough”* and change is scary and hard.&lt;/p&gt;

&lt;p&gt;What do we need? We need tools. The &lt;a href=&#34;http://rpki.surfnet.nl/&#34;&gt;RPKI dashboard&lt;/a&gt; that SURFnet has available is a fantastic example of an easy to use tool that makes a ton of information available. We need a &lt;strong&gt;&lt;em&gt;very easy&lt;/em&gt;&lt;/strong&gt; way to deploy this. BGP is actually a pretty simple protocol to make work, which is why is hasn’t changed much in the  extremely long tenure it has had as foundation of the internet. We need a very, very straightforward way to get the non-technical pieces done.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; This is just the tip of the iceberg and I am but a novice with this tech - but my gut feelings are typically right about this type of thing.&lt;/p&gt;

&lt;p&gt;* &amp;ldquo;Good enough” is almost never good enough.&lt;/p&gt;

&lt;h6 id=&#34;image-created-from-surfnet-rpki-page&#34;&gt;Image created from SURFNet RPKI page.&lt;/h6&gt;
</description>
    </item>
    
    <item>
      <title>Buzzwords, technology, terminology, and the interconnection of modern networking</title>
      <link>https://forwardingplane.net/post/buzzwords-technology-terminology-interconnection-modern-networking/</link>
      <pubDate>Mon, 18 Jan 2016 16:33:09 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/buzzwords-technology-terminology-interconnection-modern-networking/</guid>
      <description>&lt;p&gt;&lt;em&gt;I&amp;rsquo;m way overdue for a soapbox session &amp;ndash; I found this one in my drafts and thought it was something I needed to put out there. It&amp;rsquo;s already dated in terminology but that actually helps make the point - it&amp;rsquo;s hard to keep up. &lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Lets throw this out there: social media can be exhausting. Do not misunderstand me, it’s a great tool for communication, obtaining and disseminating information as well as standard goofing around. It’s also a serious business for a huge amount of companies. I use it extensively myself and I’ll assume there is a pretty good chance you followed a tweet or other social media link to get here. However, for a green network engineer looking for a path forward it can be a bit daunting. Those my age never had the social media aspect to deal with when we were learning, we may have had IRC or other haphazard back channels to bounce ideas and questions, but for the most part, the resources were far more limited than they are today. In actuality, I believe that this was a bit of an advantage that we had over today: we were often forced to bulldoze through problems, making mistakes that taught us deep understandings of the inner working of that given technology. It also sucked a lot more [time].&lt;/p&gt;

&lt;p&gt;Am I right? Maybe. Maybe not. Who is to say? These days I take full advantage of the wealth of information that is the internet for both personal and professional tasks, I would be a tad crazy not to. It&amp;rsquo;s why I write the tech stuff I write.&lt;/p&gt;

&lt;p&gt;With all of that, though, comes so many buzzwords and so much hype that it is very easy for an aspiring network engineer (or any professional IT hopeful, student or casual techie) to become completely overwhelmed by simply looking at twitter and following a handful of key players. I’ve been doing what I do with networks since the 1990s and even I have been feeling a little overwhelmed by the sheer number of “Network Engineer Killer” or “Must know” technologies being thrown around in the last few years. It&amp;rsquo;s both exciting, encouraging and at the same time enough to make even the most grizzly engineer feel snowed under.&lt;/p&gt;

&lt;p&gt;Wait for it……Cloud. No wait, DevOps. Containers! NO! NO! SDN! They&amp;rsquo;re all cool and they&amp;rsquo;re all important. They are also a lot to take in.&lt;/p&gt;

&lt;p&gt;I have been thinking a great deal about DevOps and SDN lately. Being a really, really bad developer, DevOps is a tad uncomfortable for me. It is an obviously useful skill set: Understanding code and automation. It’s powerful and &lt;strong&gt;will&lt;/strong&gt; make your professional life easier. Do you need to obsess over it? Probably not (do you need to obsess over any of it?!?). Remember that internet thing that I mentioned before? Yeah, there are a lot of resources there. Search engines are your friend.&lt;/p&gt;

&lt;p&gt;Will you need to know the concepts? For sure. Guess what, though? There are a &lt;strong&gt;ton&lt;/strong&gt; of resources for that too.&lt;/p&gt;

&lt;p&gt;As I was brainstorming this, I mind-mapped some of the things that jumped into my brain [&lt;a href=&#34;https://mindnode.com/&#34;&gt;mindnode pro&lt;/a&gt; is a fantastic app for this, I highly recommend it]. Things that get a lot of attention and maybe deserve a cursory glance. Lets break them down in a simple-ish and concise-ish manner and understand that by the time of this writing I’m positive it will be outdated and there will be some new whiz-bang thing that the marketing machine will be saying is the “something-killer&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Here are the high level things I see thrown around a lot. For what it’s worth, OpenDayLight has &lt;a href=&#34;http://www.opendaylight.org/project/technical-overview&#34;&gt;a page&lt;/a&gt; with some definitions that is pretty good, too.&lt;/p&gt;

&lt;p&gt; &lt;a href=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/07/Networking-Tech-Relationships.png&#34;&gt;&lt;img src=&#34;http://www.forwardingplane.net/wp-content/uploads/2015/07/Networking-Tech-Relationships.png&#34; alt=&#34;Networking Tech Relationships&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is absolutely &lt;strong&gt;not&lt;/strong&gt; all-encompassing and is likely missing major things, however, the point is really not to be accurate as much as it is to demonstrate that there is a &lt;strong&gt;monumental&lt;/strong&gt; amount of scope that is in some ways interconnected and in other ways completely autonomous. It is also pretty clear that due to the nature of what “DevOps” is, it has ties into many other things.&lt;/p&gt;

&lt;p&gt;The biggest take-away is that the communication paths need to be there - Better communication between these specializations makes for better, more secure, more usable tools.&lt;/p&gt;

&lt;p&gt;It is how the DevOps is done, &lt;strong&gt;not&lt;/strong&gt; what it is doing.&lt;/p&gt;

&lt;p&gt;What I am really getting at here is that there is no need to get overwhelmed. You don’t need to know all of this stuff. If you know a little about most of it and a lot about one or two topics, then in my opinion you are doing really, really well.&lt;/p&gt;

&lt;p&gt;My best advice to any new IT person is not to know everything but to know where to find it - and then share what you learned.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building Interdomain SDN part 3</title>
      <link>https://forwardingplane.net/post/building-interdomain-sdn-part-3/</link>
      <pubDate>Fri, 06 Nov 2015 04:37:23 +0000</pubDate>
      
      <guid>https://forwardingplane.net/post/building-interdomain-sdn-part-3/</guid>
      <description>&lt;p&gt;A few years ago I wrote &lt;a href=&#34;http://www.forwardingplane.net/2012/11/sdn-across-domains-in-the-wan-a-novice-look/&#34;&gt;some text&lt;/a&gt; on &lt;a href=&#34;http://www.forwardingplane.net/2013/01/sdn-across-the-wan-part-deux-primitives/&#34;&gt;interdomain SDN&lt;/a&gt;. Years later, work is being done, smart people are thinking about it and building ways to make it a reality. Not being one to give up on an idea, I gave &lt;a href=&#34;https://docs.google.com/presentation/d/1anAaqWR8wmzKO5fqidDy9QJXW4RiVshX9Miq3PoDv9E/edit&#34;&gt;this presentation&lt;/a&gt; in may at &lt;a href=&#34;http://chinog.org/meetings/chi-nog-05/&#34;&gt;ChiNOG&lt;/a&gt;  on what my take on what that architecture should be. I (we) propose that the use of existing protocols such as &lt;a href=&#34;https://tools.ietf.org/html/rfc5575&#34;&gt;BGP FlowSpec&lt;/a&gt; will make this realistically deployable and maintainable given some &lt;a href=&#34;https://github.com/dwcarder/sdn-ix-demo&#34;&gt;simple, pluggable middleware&lt;/a&gt;. As work continues to happen on this, my belief is that this is a very sound (and simple) concept. The middleware is modular and flexible enough that it can stand alone or plug into an existing code base such as ODL or Ryu. As &lt;a href=&#34;http://sc15blog.blogspot.com/2015/11/simplifying-worlds-most-powerful.html&#34;&gt;I work on the SDN deployment&lt;/a&gt; for the &lt;a href=&#34;http://www.sc15.org&#34;&gt;annual international supercomputing conference&lt;/a&gt;, and work on the &lt;a href=&#34;https://www.es.net/network-r-and-d/workshops/&#34;&gt;SDN for scientific networking workshop&lt;/a&gt;,  I become more and more convinced that there needs to be an operationally viable and simple way to support these types of networks in ways that are thin and simple since it is a newer concept and some of the protocols involved (e.g. OpenFlow) is still in its infancy.  Here is the video of the talk for anyone interested in listening to me talk about it for 20 minutes. As a reference, this is a great talk from the same conference on BGP FlowSpec that adds a lot of credence to the use of it as a policy dissemination protocol.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
